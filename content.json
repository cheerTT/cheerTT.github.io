{"meta":{"title":"cheerttの个人博客","subtitle":"记录学习、分享生活","description":"不是学霸，但也不渣","author":"cheertt","url":"http://cheertt.top"},"pages":[],"posts":[{"title":"Ubuntu16.04 安装CUDA9.0和cuDNN7.4.1","slug":"Ubuntu16.04 安装CUDA9.0和cuDNN7.4.1","date":"2019-08-02T11:04:38.419Z","updated":"2019-08-02T11:15:20.367Z","comments":true,"path":"p/17317.html","link":"","permalink":"http://cheertt.top/p/17317.html","excerpt":"","text":"【step by step】超简单Ubuntu16.04 安装CUDA9.0和cuDNN7.4.1 1 准备（1）下载CUDA9.0 从官网下载 https://developer.nvidia.com/cuda-toolkit-archive 点进去之后下载下面的五个文件 （2）下载cuDNN7.4.1 （3）最终一共下载6个文件 2 安装CUDA（1）输入 nvidia-smi若不显示下面的驱动基本信息或者驱动版本小于384，则需要先安装驱动。 打开【软件与更新】选择【附加驱动】如下图所示勾选即可成功安装驱动，注意安装完成之后需要重启电脑。 （2）安装cuda9.0 chmod +x ./cuda_9.0.176_384.81_linux.run sudo ./cuda_9.0.176_384.81_linux.run ctrl + c 然后按照下图内容键入accept,yes或者no 接下来把补丁都安装上去，安装过程与上面相同。 1234sudo ./cuda_9.0.176.1_linux.runsudo ./cuda_9.0.176.2_linux.runsudo ./cuda_9.0.176.3_linux.runsudo ./cuda_9.0.176.4_linux.run 配置环境变量 sudo vim ~/.bashrc 在文件底部输入下面两句话 12export PATH=/usr/local/cuda-9.0/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64$LD_LIBRARY_PATH source ~/.bashrc （3）验证是否安装成功 123cd cd ~/NVIDIA_CUDA-9.0_Samples/1_Utilities/deviceQuery sudo make ./deviceQuery 3 安装cuDNN7.4.1（1）解压cudnn7.4.1进入到include目录执行一下操作 sudo cp cudnn.h /usr/local/cuda/include （2）再进入lib64目录下进行以下操作 12345sudo cp lib* /usr/local/cuda/lib64cd /usr/local/cuda/lib64sudo rm -rf libcudnn.so libcudnn.so.7sudo ln -s libcudnn.so.7.4.1 libcudnn.so.7sudo ln -s libcudnn.so.7 libcudnn.so （3）执行以下命令验证是否安装成功 nvcc -V","categories":[{"name":"coding","slug":"coding","permalink":"http://cheertt.top/categories/coding/"}],"tags":[{"name":"教程","slug":"教程","permalink":"http://cheertt.top/tags/教程/"},{"name":"‘Ubuntu’","slug":"‘Ubuntu’","permalink":"http://cheertt.top/tags/‘Ubuntu’/"}],"keywords":[{"name":"coding","slug":"coding","permalink":"http://cheertt.top/categories/coding/"}]},{"title":"PyTorch入门实践","slug":"PyTorch入门实践","date":"2019-08-01T07:48:52.974Z","updated":"2019-08-01T12:13:13.567Z","comments":true,"path":"p/9984.html","link":"","permalink":"http://cheertt.top/p/9984.html","excerpt":"","text":"0 简介本博客笔记主要根据 《深度学习框架PyTorch：入门与实践》 整理而来，知识要点不算详细，主要为了知识点框架的罗列。 1 PyTorch简介Tensorflow、PyTorch、MXNet 几乎所有的框架都是基于计算图的，而计算图又分为静态计算图和动态计算图。静态计算图先定义再运行(define and run)，一次定义多次运行，而动态计算图是在运行过程中被定义的，在运行时构建(define by run)，可以多次构建多次运行。PyTorch和Tensorflow都是基于计算图的深度学习框架，PyTorch使用的是动态图，而Tensorflow使用的是静态图。在PyTorch中每一次前向传播（每一次运行代码）都会创建一幅新的计算图。 静态图一旦创建就不能修改，而且静态图定义的时候，使用了特殊的语法，就像新学的一门语言。这还意味着你无法使用if、while、for-loop等常用的Python语句。因此静态图不得不为这些操作专门设计语法，同时在构件图的时候必须把所有可能出现的情况都包含进去，这也导致了静态图过于庞大，可能占用过高的显存。动态图框架就没有这个问题，它可以使用Python的if、while、for-loop等条件语句，最终创建的计算图取决于你执行的条件分支。 动态图的思想直观明了，更符合人的思考过程。动态图的方式使得我们可以任意修改前向传播，还可以随时查看变量的值。如果说静态图框架好比C++，每次运行都要编译才行(session.run)，那么动态图框架就是Python,动态执行，可以交互式查看修改。 动态图带来的另一个优势是调试更容易，在PyTorch中，代码报错的地方，往往就是你写错代码的地方，而静态图需要先根据你的代码生成Graph对象，然后在session.run()时报错，这种报错几乎很难找到对应的代码中真正的错误的地方。 PyTorch的设计遵循 tensor -&gt; variable(autograd) -&gt; nn.Module三个由低到高的抽象层次，分别代表高维数组(张量)、自动求导(变量)和神经网络(层/模块)，而且这三个抽象之间联系紧密，可以同时进行修改和操作。 2 快速入门2.1 Tensor函数名后面带下划线的函数会修改tensor本身。 tensor和numpy对象共享内存，所以它们之间的转换很快，而且几乎不消耗资源。 2.2 autogradautograd.Variable是Autograd中的核心类，它简单封装了Tensor，并支持几乎所有Tensor的操作。Tensor被封装成Variable之后，可以调用它的.backward实现反向传播，自动计算所有梯度。 Variable主要包含三个属性： data: 保存Variable所包含的Tensor grad: 保存data对应的梯度，grad也是个Variable，而不是tensor，他和data的形状一样 grad_fn: 指向一个Functions对象，这个Function用来反向传播计算输入的梯度 grad在反向传播过程中是累加的，这意味着每次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。 Variable和Tensor具有近乎一致的接口，在实际使用中可以无缝切换。 2.3 神经网络torch.nn是专门为神经网络设计的模块化接口，nn构建于autograd之上，可以来定义和运行神经网络。可以把它看作一个网络的封装，包含网络各层定义及forward方法，调用forward(input)方法，可返回前向传播的结果。 定义网络 定义网络时，需要继承nn.Module，并实现它的forward方法，把网络中具有可学习参数的层放在构造函数__init__中。如果某一层（如ReLU）不具有可学习参数，则既可以放在构造函数中，也可以不放。另外，nn.Module子类的函数必须在构造函数中执行父类的构造函数。 只要在nn.Module的子类中定义了forward函数，backward函数就会被自动实现（利用autograd）。在forward函数中可使用任何Variable支持的函数，还可以使用if、for循环、print、log等Python语法。 网络的可学习参数通过net.parameters()返回，net.named_parameters可同时返回可学习的参数及名称。 forward函数的输入和输出都是Variable，只有Variable才具有自动求导的功能，Tensor是没有的，所以在输入时，需要把Tensor封装成Variable。 损失函数 nn实现了神经网络中大多数的损失函数。 优化器 在反向传播计算完所有参数的梯度后，还需要使用优化方法更新网络的权重 2.4 数据加载与预处理torchvision实现了常用的图像数据加载功能，例如ImageNet、CIFAR10、MNIST等，以及常用的数据转换操作，方便数据加载。 Dataset对象是一个数据集，可按下标访问，返回形如（data, label）的数据。 DataLoader是一个可迭代对象，它将dataset返回的每一条数据样本拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，对DataLoader也完成了一次迭代。 3 Tensor和autograd3.1 Tensor从接口的角度将，对tensor的操作可分为两类： torch.function，如torch.save等 tensor.function，如tensor.view等 为方便使用，对tensor的大部分操作同时支持这两个接口。如torch.sum(a, b)和a.sum(b)功能等价。 从存储角度讲，对tensor的操作又可以分为两类： 不会修改自身的数据，如a.add(b)，加法的结果会返回一个新的tensor 会修改自身的数据，如a.add_(b)，加法的结果仍存储在a中，a被修改了 函数以_结尾的都是inplace操作，即会修改调用者自己的数据，在实际应用中需加以区分。 t.Tensor(*sizes)创建tensor时，系统不会马上分配空间，只会计算剩余的内存是否足够使用，使用到tensor时才会分配，而其他操作都是在创建完tensor后马上进行空间分配。 常用tensor操作 通过tensor.view方法可以调整tensor的形状，但必须保证调整前后元素总数一致。view不会修改自身的数据，返回的新tensor和源tensor共享内存。resize是另一种调整size的方法，但与view不同，它可以修改tensor的尺寸。 内部结构 tensor分为头信息区和存储区，信息区主要保存着tensor的形状（size）,步长（stride）,数据类型（type）等信息，而真正的数据则保存成连续数组。由于数据动辄成千上万，因此信息区元素占用内存较少，主要内存占用取决于tensor中元素的数目，即存储区的大小。 向量化 向量化计算是一种特殊的并行计算方式，一般程序在同一时间只执行一个操作方式，它可在同一时间执行多个操作，通常是对不同的数据执行同样的一个或一批指令，或者说把指令应用在一个数组/向量上。向量化可极大提高科学运算的效率。 大多数t.function都有一个参数out，这时产生的结果将保存在out指定的tensor之中； t.set_num_threads可以设置PyTroch进行CPU多线程并行计算时所占用的线程数，用来限制PyTorch所占用的CPU数目； t.set_printoptions可以用来设置打印tensor时的数值精度和格式； 3.2 autogradVariable PyTorch在autograd模块中实现了计算图的相关功能，autograd中的核心数据结构是Variable。Variable封装了tensor，并记录对tensor的操作记录用来构建计算图。 Variable的构造函数需要传入tensor,同时有两个可选参数： data: 需要传入的tensor requires_grad(bool): 是否需要对该Variable进行求导 volatile(bool): 意为“挥发”，设置为True,构建在该variable之上的图都不会自动求导，专为推理阶段设计 PyTorch使用的是动态图，它的计算图在每次前向传播时都是从头开始构建的，所以它能够使用Python控制语句，根据需求创建计算图。这一点在自然语言处理领域很有用。 只有对variable的操作才能使用autograd，如果对variable的data直接进行操作，将无法使用反向传播。除了参数初始化，一般我们不会直接修改variable.data的值。 4 神经网络工具箱nn将模型的所有参数转存到GPU上，model = model.cuda()上 将输入数据放置到GPU上，input.cuda() 多个GPU并行计算 new_net = nn.DataParallel(net, device_ids=[0, 1]) output = new_net(input) output = nn.parallel.data.parallel(net, input, device_ids=[0, 1]) layer = Linear(4, 3)相当于函数，实际上它的调用过程是layer.__call__(input)，在__call__函数中调用layer.forward(x)。所以尽量使用layer(x)而不是layer.forward(x) 支持inplace的操作一般都是节省内存或者显存的。 5 PyTorch中常用的工具在训练神经网络的过程中需要用到很多工具，其中最重要的三部分是数据、可视化和GPU加速。 5.1 数据处理数据加载 在PyTorch中，数据加载可通过自定义的数据集对象实现。数据集对象被抽象为Dataset类，实现自定义的数据集需要继承Dataset，并实现两个Python的魔法方法。 __getitem__：返回一条数据或一个样本。obj[index]等价于obj.__getitem__(index) __len__：返回样本的数量。len(obj)等价于obj.__len() DataLoader里没有太多的魔法方法，他封装了Python的标准库multiprocessing,使其能够实现多进程加速。在Dataset和Dataloader的使用方法有如下建议。 高负载的操作放在__getitem__中，如加载图片； dataset中应尽量只包含只读对象，避免修改任何可变对象； 在从事大多数深度学习研究时，程序都需要实现以下几个功能。 模型定义 数据处理和加载 训练模型（Train &amp; Validate） 训练过程的可视化 测试（Test / Inference） 此外，程序还应该满足以下几个要求：模型需具有高度的可配置性，便于修改参数，修改模型和反复实验；代码应具有良好的组织结构，使人一目了然；代码应具有良好的说明，使其他人能够理解。 上述过程中，最重要的是模型定义、数据加载、训练和测试 5.2 使用GPU加速:CUDA在PyTorch中，一下数据结构分为CPU和GPU两个版本：Tensor、Variable(包括Parameter)、nn.Module(包括常用的layer、loss function、以及容器Sequential等) 它们都带有一个.cuda方法，调用此方法即可将其转为对应的GPU对象。注意，tensor.cuda和variable.cuda都会返回一个新对象，这个新对象的数据已转移至GPU，而之前的tensor/variable的数据还在原来的设备上（CPU）。module.cuda会将所有的数据都迁移至GPU，并返回自己。所以module = module.cuda() 和 module.cuda() 的效果相同。 Variable和nn.Module在GPU和CPU之间的转换，本质上还是利用了Tensor在GPU和CPU之间的转换。Variable.cuda操作实际上是将variable.data转移至指定的GPU。而nn.Module的cuda方法是将nn.Module下的所有parameter（包括子module的parameter）都转移至GPU，而Partameter本质上也是Variable。 关于使用GPU的一些建议： GPU运算很快，但是运算量小时，并不能体现他的优势，因此一些简单的操作直接用CPU完成； 数据在CPU和GPU之间的传递比较耗时，应当尽量避免； 在进行低精度的运算时，可以考虑HalfTensor，相比FloatTensor能节省一半的显存，但是千万注意数据溢出的情况； 大部分的损失函数也都属于nn.Module，但在使用GPU时，很多时候我们忘记使用它的.cuda方法，在大多数情况下不会报错，因为损失函数本身没有可学习的参数。但是某些情况下会出现问题，为了保险起见同时也为了代码更规范，应记得调用criterion.cuda。 5.3 持久化在PyTorch中，一下对象可以持久化到硬盘，并通过相应的方法加载到内存中。 Tensor、Variable、nn.Module、Optimizer 本质上，上述这些信息最终都是保存成Tensor。Tensor的保存和加载十分简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的pickle模块，在load时还可以将GPU tensor映射到CPU或其他GPU上。 5.4 ipdb关于ipdb的使用还有一些技巧： &lt;tab&gt;键能够自动补齐，补齐用法和IPython中的类似； j(ump) &lt;lineno&gt;能够跳过中间某些行代码的执行； h(elp)能够查看调试命令的用法； PyTorch和ipdb结合能完成很多其他框架不能完成或很难实现的功能： 通过debug暂停程序。当程序进入debug模式之后，将不再执行GPU和CPU运算，但是内存和显存及相应的堆栈空间不会释放； 通过debug分析程序，查看每个层的输出，查看网络的参数情况。通过u(p)、d(own)、s(tep)等命令，能够进入指定的代码，通过n(ext)可以单步执行，从而看到每一层的运算结果，便于分析网络的数值分布等信息。 作为动态图框架，PyTorch拥有Python动态语言解释执行的优点，我们能够在运行程序时，通过ipdb修改某些变量的值或属性，这些修改能够立即生效。例如可以在训练不久根据损失函数调整学习率，不必重启程序。","categories":[{"name":"notebook","slug":"notebook","permalink":"http://cheertt.top/categories/notebook/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://cheertt.top/tags/笔记/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://cheertt.top/tags/PyTorch/"}],"keywords":[{"name":"notebook","slug":"notebook","permalink":"http://cheertt.top/categories/notebook/"}]},{"title":"cs231n的NumPy教程","slug":"cs231n的NumPy教程","date":"2019-07-31T14:19:23.857Z","updated":"2019-08-01T12:13:40.552Z","comments":true,"path":"p/39949.html","link":"","permalink":"http://cheertt.top/p/39949.html","excerpt":"","text":"0 简介本博客笔记主要根据 斯坦福NumPy教程 整理而来，虽然这是一篇入门笔记，但不适合新手看。因为此笔记只是一个知识点框架的罗列，里面所用到的接口并没有做详细的说明，而且接口的细节也只是挑重点罗列，并没做到面面俱到，特别是笔记的第3、4部分，只是对其的简单介绍。整理此笔记只是为了对Python以及Numpy的基本知识点的简单回顾。 1 Python1.1 基本数据类型像大多数语言一样，Python有许多基本数据类型，包括：integer、float、boolean、string。这些数据类型的作用和特性和其他编程语言一样。Python不支持自增、自减操作。x++ 、x-- 12345678910111213141516171819202122232425262728293031323334353637383940414243# Numbersx = 3print(type(x)) # Prints \"&lt;class 'int'&gt;\"print(x) # Prints \"3\"print(x + 1) # Addition; prints \"4\"print(x - 1) # Subtraction; prints \"2\"print(x * 2) # Multiplication; prints \"6\"print(x ** 2) # Exponentiation; prints \"9\"x += 1print(x) # Prints \"4\"x *= 2print(x) # Prints \"8\"y = 2.5print(type(y)) # Prints \"&lt;class 'float'&gt;\"print(y, y + 1, y * 2, y ** 2) # Prints \"2.5 3.5 5.0 6.25\"# Booleant = Truef = Falseprint(type(t)) # Prints \"&lt;class 'bool'&gt;\"print(t and f) # Logical AND; prints \"False\"print(t or f) # Logical OR; prints \"True\"print(not t) # Logical NOT; prints \"False\"print(t != f) # Logical XOR; prints \"True\"# Stringhello = 'hello' # String literals can use single quotesworld = \"world\" # or double quotes; it does not matter.print(hello) # Prints \"hello\"print(len(hello)) # String length; prints \"5\"hw = hello + ' ' + world # String concatenationprint(hw) # prints \"hello world\"hw12 = '%s %s %d' % (hello, world, 12) # sprintf style string formattingprint(hw12) # prints \"hello world 12\"s = \"hello\"print(s.capitalize()) # Capitalize a string; prints \"Hello\"print(s.upper()) # Convert a string to uppercase; prints \"HELLO\"print(s.rjust(7)) # Right-justify a string, padding with spaces; prints \" hello\"print(s.center(7)) # Center a string, padding with spaces; prints \" hello \"print(s.replace('l', '(ell)')) # Replace all instances of one substring with another; # prints \"he(ell)(ell)o\"print(' world '.strip()) # Strip leading and trailing whitespace; prints \"world\" 1.2 容器Python容器包含的类型：list 、dict、 set、 tuple 1.2.1 列表12345678910111213141516171819202122232425262728293031323334353637383940414243xs = [3, 1, 2] # Create a listprint(xs, xs[2]) # Prints \"[3, 1, 2] 2\"print(xs[-1]) # Negative indices count from the end of the list; prints \"2\"xs[2] = 'foo' # Lists can contain elements of different typesprint(xs) # Prints \"[3, 1, 'foo']\"xs.append('bar') # Add a new element to the end of the listprint(xs) # Prints \"[3, 1, 'foo', 'bar']\"x = xs.pop() # Remove and return the last element of the listprint(x, xs) # Prints \"bar [3, 1, 'foo']\"# 切片nums = list(range(5)) # range is a built-in function that creates a list of integersprint(nums) # Prints \"[0, 1, 2, 3, 4]\"print(nums[2:4]) # Get a slice from index 2 to 4 (exclusive); prints \"[2, 3]\"print(nums[2:]) # Get a slice from index 2 to the end; prints \"[2, 3, 4]\"print(nums[:2]) # Get a slice from the start to index 2 (exclusive); prints \"[0, 1]\"print(nums[:]) # Get a slice of the whole list; prints \"[0, 1, 2, 3, 4]\"print(nums[:-1]) # Slice indices can be negative; prints \"[0, 1, 2, 3]\"nums[2:4] = [8, 9] # Assign a new sublist to a sliceprint(nums) # Prints \"[0, 1, 8, 9, 4]\"# 循环# 循环获取列表元素animals = ['cat', 'dog', 'monkey']for animal in animals: print(animal)# Prints \"cat\", \"dog\", \"monkey\", each on its own line.# 循环获取列表元素，且包含下标animals = ['cat', 'dog', 'monkey']for idx, animal in enumerate(animals): print('#%d: %s' % (idx + 1, animal))# Prints \"#1: cat\", \"#2: dog\", \"#3: monkey\", each on its own line# 列表于循环的一种嵌套用法nums = [0, 1, 2, 3, 4]squares = [x ** 2 for x in nums]print(squares) # Prints [0, 1, 4, 9, 16]# 列表循环也可以带有一些简单的判断nums = [0, 1, 2, 3, 4]even_squares = [x ** 2 for x in nums if x % 2 == 0]print(even_squares) # Prints \"[0, 4, 16]\" 1.2.2 字典123456789101112131415161718192021222324252627# 字典就是一组键值对，和Java中的Map类似d = &#123;'cat': 'cute', 'dog': 'furry'&#125; # Create a new dictionary with some dataprint(d['cat']) # Get an entry from a dictionary; prints \"cute\"print('cat' in d) # Check if a dictionary has a given key; prints \"True\"d['fish'] = 'wet' # Set an entry in a dictionaryprint(d['fish']) # Prints \"wet\"# print(d['monkey']) # KeyError: 'monkey' not a key of dprint(d.get('monkey', 'N/A')) # Get an element with a default; prints \"N/A\"print(d.get('fish', 'N/A')) # Get an element with a default; prints \"wet\"del d['fish'] # Remove an element from a dictionaryprint(d.get('fish', 'N/A')) # \"fish\" is no longer a key; prints \"N/A\"# 循环d = &#123;'person': 2, 'cat': 4, 'spider': 8&#125;for animal in d: legs = d[animal] print('A %s has %d legs' % (animal, legs))# Prints \"A person has 2 legs\", \"A cat has 4 legs\", \"A spider has 8 legs\"d = &#123;'person': 2, 'cat': 4, 'spider': 8&#125;for animal, legs in d.items(): print('A %s has %d legs' % (animal, legs))# Prints \"A person has 2 legs\", \"A cat has 4 legs\", \"A spider has 8 legs\"nums = [0, 1, 2, 3, 4]even_num_to_square = &#123;x: x ** 2 for x in nums if x % 2 == 0&#125;print(even_num_to_square) # Prints \"&#123;0: 0, 2: 4, 4: 16&#125;\" 1.2.3 集合123456789101112131415161718192021# 集合中不能包含重复元素，集合是无序的animals = &#123;'cat', 'dog'&#125;print('cat' in animals) # Check if an element is in a set; prints \"True\"print('fish' in animals) # prints \"False\"animals.add('fish') # Add an element to a setprint('fish' in animals) # Prints \"True\"print(len(animals)) # Number of elements in a set; prints \"3\"animals.add('cat') # Adding an element that is already in the set does nothingprint(len(animals)) # Prints \"3\"animals.remove('cat') # Remove an element from a setprint(len(animals)) # Prints \"2\"# 循环animals = &#123;'cat', 'dog', 'fish'&#125;for idx, animal in enumerate(animals): print('#%d: %s' % (idx + 1, animal))# Prints \"#1: fish\", \"#2: dog\", \"#3: cat\"from math import sqrtnums = &#123;int(sqrt(x)) for x in range(30)&#125;print(nums) # Prints \"&#123;0, 1, 2, 3, 4, 5&#125;\" 1.2.4 元组123456# 元组是有序列表，其值是不可变的d = &#123;(x, x + 1): x for x in range(10)&#125; # Create a dictionary with tuple keyst = (5, 6) # Create a tupleprint(type(t)) # Prints \"&lt;class 'tuple'&gt;\"print(d[t]) # Prints \"5\"print(d[(1, 2)]) # Prints \"1\" 1.3 函数Python函数的是用关键字def定义的。 123456789101112131415161718192021def sign(x): if x &gt; 0: return 'positive' elif x &lt; 0: return 'negative' else: return 'zero'for x in [-1, 0, 1]: print(sign(x))# Prints \"negative\", \"zero\", \"positive\"# 带有可选参数的函数def hello(name, loud=False): if loud: print('HELLO, %s!' % name.upper()) else: print('Hello, %s' % name)hello('Bob') # Prints \"Hello, Bob\"hello('Fred', loud=True) # Prints \"HELLO, FRED!\" 1.4 类12345678910111213141516class Greeter(object): # Constructor def __init__(self, name): self.name = name # Create an instance variable # Instance method def greet(self, loud=False): if loud: print('HELLO, %s!' % self.name.upper()) else: print('Hello, %s' % self.name)g = Greeter('Fred') # Construct an instance of the Greeter classg.greet() # Call an instance method; prints \"Hello, Fred\"g.greet(loud=True) # Call an instance method; prints \"HELLO, FRED!\" 2 NumpyNumpy是用Python实现的一个科学计算的核心库。它提供了一个高性能的高维数组对象。 2.1 数组12345678910111213141516171819202122232425262728293031323334import numpy as npa = np.array([1, 2, 3]) # Create a rank 1 arrayprint(type(a)) # Prints \"&lt;class 'numpy.ndarray'&gt;\"print(a.shape) # Prints \"(3,)\"print(a[0], a[1], a[2]) # Prints \"1 2 3\"a[0] = 5 # Change an element of the arrayprint(a) # Prints \"[5, 2, 3]\"b = np.array([[1,2,3],[4,5,6]]) # Create a rank 2 arrayprint(b.shape) # Prints \"(2, 3)\"print(b[0, 0], b[0, 1], b[1, 0]) # Prints \"1 2 4\"# numpy提供一些函数创建数组对象import numpy as npa = np.zeros((2,2)) # Create an array of all zerosprint(a) # Prints \"[[ 0. 0.] # [ 0. 0.]]\"b = np.ones((1,2)) # Create an array of all onesprint(b) # Prints \"[[ 1. 1.]]\"c = np.full((2,2), 7) # Create a constant arrayprint(c) # Prints \"[[ 7. 7.] # [ 7. 7.]]\"d = np.eye(2) # Create a 2x2 identity matrixprint(d) # Prints \"[[ 1. 0.] # [ 0. 1.]]\"e = np.random.random((2,2)) # Create an array filled with random valuesprint(e) # Might print \"[[ 0.91940167 0.08143941] # [ 0.68744134 0.87236687]]\" 2.2 数组索引123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import numpy as np# Create the following rank 2 array with shape (3, 4)# [[ 1 2 3 4]# [ 5 6 7 8]# [ 9 10 11 12]]a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])# Use slicing to pull out the subarray consisting of the first 2 rows# and columns 1 and 2; b is the following array of shape (2, 2):# [[2 3]# [6 7]]b = a[:2, 1:3]# A slice of an array is a view into the same data, so modifying it# will modify the original array.print(a[0, 1]) # Prints \"2\"b[0, 0] = 77 # b[0, 0] is the same piece of data as a[0, 1]print(a[0, 1]) # Prints \"77\"import numpy as np# Create the following rank 2 array with shape (3, 4)# [[ 1 2 3 4]# [ 5 6 7 8]# [ 9 10 11 12]]a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])# Two ways of accessing the data in the middle row of the array.# Mixing integer indexing with slices yields an array of lower rank,# while using only slices yields an array of the same rank as the# original array:row_r1 = a[1, :] # Rank 1 view of the second row of arow_r2 = a[1:2, :] # Rank 2 view of the second row of aprint(row_r1, row_r1.shape) # Prints \"[5 6 7 8] (4,)\"print(row_r2, row_r2.shape) # Prints \"[[5 6 7 8]] (1, 4)\"# We can make the same distinction when accessing columns of an array:col_r1 = a[:, 1]col_r2 = a[:, 1:2]print(col_r1, col_r1.shape) # Prints \"[ 2 6 10] (3,)\"print(col_r2, col_r2.shape) # Prints \"[[ 2] # [ 6] # [10]] (3, 1)\" # 整数索引import numpy as npa = np.array([[1,2], [3, 4], [5, 6]])# An example of integer array indexing.# The returned array will have shape (3,) andprint(a[[0, 1, 2], [0, 1, 0]]) # Prints \"[1 4 5]\"# The above example of integer array indexing is equivalent to this:print(np.array([a[0, 0], a[1, 1], a[2, 0]])) # Prints \"[1 4 5]\"# When using integer array indexing, you can reuse the same# element from the source array:print(a[[0, 0], [1, 1]]) # Prints \"[2 2]\"# Equivalent to the previous integer array indexing exampleprint(np.array([a[0, 1], a[0, 1]])) # Prints \"[2 2]\"# a trickimport numpy as np# Create a new array from which we will select elementsa = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])print(a) # prints \"array([[ 1, 2, 3], # [ 4, 5, 6], # [ 7, 8, 9], # [10, 11, 12]])\"# Create an array of indicesb = np.array([0, 2, 0, 1])# Select one element from each row of a using the indices in bprint(a[np.arange(4), b]) # Prints \"[ 1 6 7 11]\"# Mutate one element from each row of a using the indices in ba[np.arange(4), b] += 10print(a) # prints \"array([[11, 2, 3], # [ 4, 5, 16], # [17, 8, 9], # [10, 21, 12]]) # 布尔类型的数组import numpy as npa = np.array([[1,2], [3, 4], [5, 6]])bool_idx = (a &gt; 2) # Find the elements of a that are bigger than 2; # this returns a numpy array of Booleans of the same # shape as a, where each slot of bool_idx tells # whether that element of a is &gt; 2.print(bool_idx) # Prints \"[[False False] # [ True True] # [ True True]]\"# We use boolean array indexing to construct a rank 1 array# consisting of the elements of a corresponding to the True values# of bool_idxprint(a[bool_idx]) # Prints \"[3 4 5 6]\"# We can do all of the above in a single concise statement:print(a[a &gt; 2]) # Prints \"[3 4 5 6]\" 2.3 数据类型1234567891011# 指定具体的数据类型import numpy as npx = np.array([1, 2]) # Let numpy choose the datatypeprint(x.dtype) # Prints \"int64\"x = np.array([1.0, 2.0]) # Let numpy choose the datatypeprint(x.dtype) # Prints \"float64\"x = np.array([1, 2], dtype=np.int64) # Force a particular datatypeprint(x.dtype) # Prints \"int64\" 2.4 数组运算12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import numpy as npx = np.array([[1,2],[3,4]], dtype=np.float64)y = np.array([[5,6],[7,8]], dtype=np.float64)# Elementwise sum; both produce the array# [[ 6.0 8.0]# [10.0 12.0]]print(x + y)print(np.add(x, y))# Elementwise difference; both produce the array# [[-4.0 -4.0]# [-4.0 -4.0]]print(x - y)print(np.subtract(x, y))# Elementwise product; both produce the array# [[ 5.0 12.0]# [21.0 32.0]]print(x * y) # 对应位置相乘print(np.multiply(x, y))# Elementwise division; both produce the array# [[ 0.2 0.33333333]# [ 0.42857143 0.5 ]]print(x / y)print(np.divide(x, y))# Elementwise square root; produces the array# [[ 1. 1.41421356]# [ 1.73205081 2. ]]print(np.sqrt(x))# 点乘import numpy as npx = np.array([[1,2],[3,4]])y = np.array([[5,6],[7,8]])v = np.array([9,10])w = np.array([11, 12])# Inner product of vectors; both produce 219print(v.dot(w))print(np.dot(v, w))# Matrix / vector product; both produce the rank 1 array [29 67]print(x.dot(v))print(np.dot(x, v))# Matrix / matrix product; both produce the rank 2 array# [[19 22]# [43 50]]print(x.dot(y))print(np.dot(x, y))# 常用计算函数import numpy as npx = np.array([[1,2],[3,4]])print(np.sum(x)) # Compute sum of all elements; prints \"10\"print(np.sum(x, axis=0)) # Compute sum of each column; prints \"[4 6]\"print(np.sum(x, axis=1)) # Compute sum of each row; prints \"[3 7]\"# 转置操作import numpy as npx = np.array([[1,2], [3,4]])print(x) # Prints \"[[1 2] # [3 4]]\"print(x.T) # Prints \"[[1 3] # [2 4]]\"# Note that taking the transpose of a rank 1 array does nothing:v = np.array([1,2,3])print(v) # Prints \"[1 2 3]\"print(v.T) # Prints \"[1 2 3]\" 2.5 广播机制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 自己实现的类似广播机制的操作import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])y = np.empty_like(x) # Create an empty matrix with the same shape as x# Add the vector v to each row of the matrix x with an explicit loopfor i in range(4): y[i, :] = x[i, :] + v# Now y is the following# [[ 2 2 4]# [ 5 5 7]# [ 8 8 10]# [11 11 13]]print(y)# 利用tile实现import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])vv = np.tile(v, (4, 1)) # Stack 4 copies of v on top of each otherprint(vv) # Prints \"[[1 0 1] # [1 0 1] # [1 0 1] # [1 0 1]]\"y = x + vv # Add x and vv elementwiseprint(y) # Prints \"[[ 2 2 4 # [ 5 5 7] # [ 8 8 10] # [11 11 13]]\" # 广播机制import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])y = x + v # Add v to each row of x using broadcastingprint(y) # Prints \"[[ 2 2 4] # [ 5 5 7] # [ 8 8 10] # [11 11 13]]\" 两个数组满足广播机制的一些条件： 让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐； 输出数组的shape是输入数组shape的各个轴上的最大值； 如果输入数组某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错； 当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值； 12345678910111213141516171819202122232425262728293031323334353637383940414243# examplesimport numpy as np# Compute outer product of vectorsv = np.array([1,2,3]) # v has shape (3,)w = np.array([4,5]) # w has shape (2,)# To compute an outer product, we first reshape v to be a column# vector of shape (3, 1); we can then broadcast it against w to yield# an output of shape (3, 2), which is the outer product of v and w:# [[ 4 5]# [ 8 10]# [12 15]]print(np.reshape(v, (3, 1)) * w)# Add a vector to each row of a matrixx = np.array([[1,2,3], [4,5,6]])# x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),# giving the following matrix:# [[2 4 6]# [5 7 9]]print(x + v)# Add a vector to each column of a matrix# x has shape (2, 3) and w has shape (2,).# If we transpose x then it has shape (3, 2) and can be broadcast# against w to yield a result of shape (3, 2); transposing this result# yields the final result of shape (2, 3) which is the matrix x with# the vector w added to each column. Gives the following matrix:# [[ 5 6 7]# [ 9 10 11]]print((x.T + w).T)# Another solution is to reshape w to be a column vector of shape (2, 1);# we can then broadcast it directly against x to produce the same# output.print(x + np.reshape(w, (2, 1)))# Multiply a matrix by a constant:# x has shape (2, 3). Numpy treats scalars as arrays of shape ();# these can be broadcast together to shape (2, 3), producing the# following array:# [[ 2 4 6]# [ 8 10 12]]print(x * 2) 3 SciPy3.1 图像运算12345678910111213141516171819from scipy.misc import imread, imsave, imresize# Read an JPEG image into a numpy arrayimg = imread('assets/cat.jpg')print(img.dtype, img.shape) # Prints \"uint8 (400, 248, 3)\"# We can tint the image by scaling each of the color channels# by a different scalar constant. The image has shape (400, 248, 3);# we multiply it by the array [1, 0.95, 0.9] of shape (3,);# numpy broadcasting means that this leaves the red channel unchanged,# and multiplies the green and blue channels by 0.95 and 0.9# respectively.img_tinted = img * [1, 0.95, 0.9]# Resize the tinted image to be 300 by 300 pixels.img_tinted = imresize(img_tinted, (300, 300))# Write the tinted image back to diskimsave('assets/cat_tinted.jpg', img_tinted) 3.2 MATLAB文件函数scipy.io.loadmat 和 scipy.io.savemat 可以读取和修改matlab文件。 3.3 点间距离函数scipy.spatial.distance.pdist 可以计算所有点之间的距离。 123456789101112131415161718import numpy as npfrom scipy.spatial.distance import pdist, squareform# Create the following array where each row is a point in 2D space:# [[0 1]# [1 0]# [2 0]]x = np.array([[0, 1], [1, 0], [2, 0]])print(x)# Compute the Euclidean distance between all rows of x.# d[i, j] is the Euclidean distance between x[i, :] and x[j, :],# and d is the following array:# [[ 0. 1.41421356 2.23606798]# [ 1.41421356 0. 1. ]# [ 2.23606798 1. 0. ]]d = squareform(pdist(x, 'euclidean'))print(d) 4 Matplotlib4.1 画图12345678910111213141516171819202122232425262728import numpy as npimport matplotlib.pyplot as plt# Compute the x and y coordinates for points on a sine curvex = np.arange(0, 3 * np.pi, 0.1)y = np.sin(x)# Plot the points using matplotlibplt.plot(x, y)plt.show() # You must call plt.show() to make graphics appear.# 更复杂的图import numpy as npimport matplotlib.pyplot as plt# Compute the x and y coordinates for points on sine and cosine curvesx = np.arange(0, 3 * np.pi, 0.1)y_sin = np.sin(x)y_cos = np.cos(x)# Plot the points using matplotlibplt.plot(x, y_sin)plt.plot(x, y_cos)plt.xlabel('x axis label')plt.ylabel('y axis label')plt.title('Sine and Cosine')plt.legend(['Sine', 'Cosine'])plt.show() 4.2 子图1234567891011121314151617181920212223import numpy as npimport matplotlib.pyplot as plt# Compute the x and y coordinates for points on sine and cosine curvesx = np.arange(0, 3 * np.pi, 0.1)y_sin = np.sin(x)y_cos = np.cos(x)# Set up a subplot grid that has height 2 and width 1,# and set the first such subplot as active.plt.subplot(2, 1, 1)# Make the first plotplt.plot(x, y_sin)plt.title('Sine')# Set the second subplot as active, and make the second plot.plt.subplot(2, 1, 2)plt.plot(x, y_cos)plt.title('Cosine')# Show the figure.plt.show() 4.3 展示图像12345678910111213141516171819import numpy as npfrom scipy.misc import imread, imresizeimport matplotlib.pyplot as pltimg = imread('assets/cat.jpg')img_tinted = img * [1, 0.95, 0.9]# Show the original imageplt.subplot(1, 2, 1)plt.imshow(img)# Show the tinted imageplt.subplot(1, 2, 2)# A slight gotcha with imshow is that it might give strange results# if presented with data that is not uint8. To work around this, we# explicitly cast the image to uint8 before displaying it.plt.imshow(np.uint8(img_tinted))plt.show()","categories":[{"name":"notebook","slug":"notebook","permalink":"http://cheertt.top/categories/notebook/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://cheertt.top/tags/笔记/"},{"name":"Python","slug":"Python","permalink":"http://cheertt.top/tags/Python/"}],"keywords":[{"name":"notebook","slug":"notebook","permalink":"http://cheertt.top/categories/notebook/"}]},{"title":"算法分析","slug":"算法分析","date":"2019-07-28T01:37:36.089Z","updated":"2019-08-01T12:12:33.980Z","comments":true,"path":"p/46253.html","link":"","permalink":"http://cheertt.top/p/46253.html","excerpt":"","text":"1 算法的基本概念1、算法的重要性：算法在计算机及软件领域中占有重要地位的一个体现。 2、算法的定义：算法是一个有限的，确定的，具有一定的输入和一些输出的有效过程。 一般认为，算法是由若干条指令组成的有穷序列，具有下列五个特征： 确定性；每条指令都是明确的、无二义的 能行性；每条指令都必须是能够执行的 输入；允许有0个或多个输入量，取自特定的集合 输出；产生一个或多个输出，他们与输入量之间存在某种特定关系 有穷性；每一条指令执行的次数都是有穷的 有穷指令序列若满足上述5条，则通常称之为算法； 只满足前4条而不满足第5条（有穷性）的有穷指令序列通常称之为计算过程； 只要不停电、机器不坏，计算过程就可以永远执行下去（死循环） 永远执行的计算过程并非毫无用处——OS就是计算过程 3、算法与其他概念的比较： 算法：定义一个任务怎样进行的一些步骤； 程序：表示算法的工具； 编程：开发程序的步骤； 软件：程序和算法； 硬件：设备 4、算法好坏的衡量尺度： 最初用计算时间来衡量一个算法的好坏， 但不同的机器之间无法相互比较，需要用独立于计算机的客观衡量标准：①问题的规模；②基本运算；③算法的计算量函数； 问题的规模：一个或多个整数，作为输入数据量的测度； 基本运算：解决给定问题时占支配地位的运算； 算法的计算量函数：用问题规模的某个函数来表示算法的基本运算量，这个表示基本运算量的函数称为算法的时间复杂度，时间复杂度用T(n)来表示。 5、渐近时间复杂度： 当问题的规模趋于极限情形时的时间复杂度，表示渐近时间复杂度的三个记号： T(n)=O(f(n)) 给出了算法时间复杂度的上界 T(n)= Ω(f(n)) 给出了算法时间复杂度的下界 T(n)= Θ(f(n)) 既给出了算法时间复杂度的上界，也给出了下界，所以为确界。 6、多项式时间与指数时间的比较： 多项式时间的算法互相之间虽有差距，一般可以接受； 指数量级时间的算法对于较大的n无实用价值 最坏情况时间复杂度：规模为n的所有输入中，基本运算执行次数最多的时间复杂度， 平均情况时间复杂度：规模为n的所有输入的算法时间复杂度的平均值，一般均假设每种输入情况以等概率出现。 7、算法研究的几个重要步骤：①设计；②表示；③确认；④分析；⑤实现和测试 设计：要根据不同的处理对象设计出高质量的算法； 表示：简明，写出的算法要保证能在计算机上实现 确认：对所有合法的输入，算法要能够得到正确的结果，对所有不合法的输入，算法都要能够正确应对。 分析：预测算法能在什么样的环境中有效的运行，在最好最坏和平均情况下能够有什么样的复杂度，还需要比较解决同一问题的不同算法各自的优缺点。 实现和测试：将所给的算法编程实现，通过各种测试来检查所给算法是否正确。 8、评价算法的主要方面： 正确性：评价算法的首要因素；程序正确性证明程序测试，即使很小的错误也可能引发巨大的连锁反应，甚至导致严重后果； 健壮性：算法/程序不仅对正确的输入要能计算出正确的结果，对不正确的输入也要能够应对处理； 简单性：算法/程序的可读性好，易调试、改进； 高效性：时间、空间复杂度较小，特别是时间复杂度； 最优性：证明所给算法是解决同一类问题中最好的； 9、算法的应用实例： Google PageRank Google Map,Baidu Map 金融领域 2 递归与分治1、排序算法及分析： 插入排序的分析： ①与输入规模有关； ②与输入序列的特性有关； 最佳情况运行时间：输入的数组已经排好序； 最坏情况运行时间：问题要求最终按递增的顺序排列，但输入数组按递减顺序排列；O(n2) 解决T(n)=2T(n/2)+cn,其中c&gt;0且c为常量；Θ(nlogn) 在最坏的情况下，归并排序比插入排序好太多。在实践中当n的规模小于30时，不管什么情况，插入排序的性能更好一些。 2、递归的概念：用函数自身给出定义的函数 递归算法：一个算法包含对自身的调用，这种调用可以是直接的，也可以是间接的。 关键是要找到递归出口和递归方程。 3、整数划分问题：递归举例 将正整数n表示成一系列正整数之和； 正整数n的不同划分个数称为正整数n的划分个数p(n); 目标：求正整数n的不同划分个数p(n) 整数划分问题是递归的一个典型问题， 引入m，将最大加数n1不大于m的划分个数记住q(n,m) 当n=m=1时，q(n,m)=1; 当n&lt;m时，q(n,m)=q(n,n); 当n=m&gt;1时，1+q(n,n-1); 当n&gt;m&gt;1时，q(n,m-1)+q(n-m,m) n=n1+n2+n3+…+nk;n1&gt;=n2&gt;=n3&gt;=n4&gt;=…&gt;=nk&gt;=1,k&gt;=1 当n1=m时，n’=n-m,即q(n-m,m) 当n1&lt;m时，q(n,m-1) 4、汉诺塔问题 分析：n=1时，直接a-&gt;b n&gt;1时，借助c实现移动，可先将n-1个圆盘按照规则a-&gt;c,再将大圆盘a-&gt;b,最后将n-1个圆盘c-&gt;b 可以通过递归实现。 5、递归的概念非常重要： 优点：结构清晰，可读性强，而且容易用数学归纳法来证明算法的正确性，为设计算法、调试程序带来很大的便利； 缺点：递归算法的运行效率较低； 递归式：当一个算法包含对自身的递归调用时，其运行时间通常可以用递归式来表示。 T(n)=2T(n/2)+Θ(n) 当n&gt;1时，T(n)=Θ(n) 当n=1时。 6、递归式的解法： 代换法（预测）； 递归树方法； 主方法； (1) 代换法： 步骤：①猜测解的形式；②用数学归纳法证明之； 只适用于解的形式很容易猜的情形； 如何猜测需要靠经验； T(n)=2T(n/2)+n T(n)=O(nlogn) T(n)=2T(n/2 + 17)+n T(n)=O(nlogn) T(n)=T(n/2)+1 T(n)=O(logn) (2) 递归树方法： ①每一个节点代表递归函数调用集合中一个子问题的代价，将所有层的代价相加得到总代价； ②当用递归式表示算法的时间复杂度时，可用递归树的方法； ③递归树方法模拟了算法的递归执行，可以由递归树方法产生对算法时间复杂度的较好猜测； (3) 主方法： T(n)=aT(n/b)+f(n);a&gt;=1,b&gt;1,a,b均为常数，f(n)是渐近正函数。 a表示子问题的个数，n/b表示问题的规模，f(n)表示分解和合并的代价； f(n)&lt;n^logba ,T(n)=Θ(n^logba) f(n)=n^logba ,T(n)=Θ(lgn x n^logba) f(n)&gt;n^logba ,T(n)=Θ(f(n)) 注意，上述三种情况没有覆盖所有的f(n) 7、分治法的基本策略/步骤： 分解：将原问题分解为子问题； 解决：求解子问题； 合并：组合子问题的解得到原问题的解； 8、分治法的使用条件： 适合分治法求解的问题一般具有以下特征： ① 问题的规模缩小到一定程度就可以容易的解决； ② 问题可以分解成若干个规模较小的相同问题，即该问题具有最优子结构性质； ③ 基于子问题的解可以合并为原问题的解； ④ 问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子问题； 9、对平衡的理解： 使子问题规模尽量接近的做法，就是平衡； 在使用分治法和递归时，要尽量把问题分成规模相等，或至少规模相近的子问题，以提高算法的效率； 是不是规模相等或者规模相差无几才算平衡？不是的。 10、分治法实例： (1) a^n (2) 快速排序 快速排序最坏时间复杂度Θ(n2),平均情况时间复杂度Θ(nlgn); 快速排序的随机化版本——主要区别在于主元的选择，不总是选择A[r]作为主元，而是从A[p…r]中随机选择一个元素作为主元。 快排通常是用于排序的最佳使用选择； 原地排序，在虚拟环境中也能很好的工作； (3) Fibonacci数列：自底向上，依次计算 (4) 矩阵乘法，直接分治的时间复杂度并不比直接计算好；Strassen的策略-只需要7次子矩阵的乘法； (5) 最大元、最小元： 给定n个数据元素，找出其中的最大元和最小元； ① 当n=2时，一次比较就可以找出两个数据元素的最大元和最小元； ② 当n&gt;2时，可以把n个数据元素分为大致相等的两半； ① 直接解法：逐个找，用n-1次比较找出最大元，用n-2次比较找出最小元，比较次数(基本运算)为2n-3次； ② 分治法：3n/2-2 (6) 最近点对： 对于平面上给定的n个点，给出距离最近的两个点； 分解：对所有点按照x坐标从小到大排序，根据下标进行分割，使得点集分成两个集合； 解决：递归寻求PL和PR中的最近点对，设其找到的最近点对的距离分别是OL和OR，置O=min(OL,OR) 合并：可能并不是O，存在这样的情况，一个点在PL中，另一个点在PR中，而且这两点之间的距离小于O，如何检查？只考虑分割线两侧各为O的点，继续压缩点的范围。 难点：如何在线性时间内获得，有论文证明，在这一片狭小区域，最多只包含7个点。 时间复杂度：O(nlogn) ① 预处理 将点对按X坐标排序；将点对按Y左边排序； ② 分解 按照X坐标将点集二分，同时获得分解后的已按Y坐标排好序的点集； ③ 递归求解 ④ 合并 找出带状区域中的点；检查带状区域中的点（已排序），计算每点与其后面7个点的距离，更新最近点对距离。 (7) 寻找顺序统计量问题： 求第i小元素问题、选择问题，设集合S中共有n个数据元素，要在S中找到第i小元素； 最小元：第一个顺序统计量； 最大元：第n个顺序统计量； 中位数：i=[(n+1)/2] ① 排序：合并排序，堆排序； ② 期望线性时间： 一般情况T(n)=T(9n/10)+Θ(n)=Θ(n); 最坏情况T(n)=T(n-1)+Θ(n)=Θ(n2); 期望线性时间的求解方法，在平均情况下，任何顺序统计量问题都可以在线性时间内得到； ① 使用random partition对数组进行划分； ② 检查主元元素是否第i小，如果是，则返回； ③ 否则，确定第i小落在划分后的低区还是高区； ④ 如果落在低区，则在低区的子数组中递归选择； ⑤ 如果落在高区，则在高区的子数组中递归选择； ③ 最坏情况线性时间： 基本思想：保证对数组的划分是好的划分， ③ 最坏情况线性时间： 11、分治法的基本思想： ① 最为常用的算法技术； ② 分治法的基本思想是将一个规模较大的问题分解为若干个规模较小的子问题，子问题相互独立且与原问题同类； ③ 求解时，首先求出这些子问题的解，然后把子问题的解组合起来就可得到原问题的解； 12、分支算法分析： 当算法包含对其自身的递归调用时，其时间复杂度通常可用递归式来表示； 分支与递归往往联系在一起； 对于递归式：可以由①代换法；②递归树法；③主方法； 3 动态规划分治法求解回顾：子问题相互独立，不包含公共子问题。动态规划与分治法类似，也是将问题分解为规模逐渐减小的同类型的子问题；与分治法不同的是，分解所得的子问题都是重复的。 动态规划相关的重要概念：（1）子问题的高度重复性；（2）最优子结构性质：问题的最优解中包含着其每一个子问题的最优解； 适合用动态规划方法求解的问题：（1）若一个问题可以分解为若干个高度重复的子问题，且问题也具有最有子结构性质，就可以用动态规划求解；（2）具体方式：可以递推的方式逐层计算最优值并记录必要的信息，最后根据记录的信息构造最优解。 动态规划的总体思想：保存已解决的子问题的答案，在需要时使用，从而避免大量重复计算。 动态规划方法解题步骤：（1）找出最优解的性质，并刻画其结构特征；（2）递归地定义最优值（写出动态规划方程）；（3）以自底向上地递推方式计算出最优值；（4）根据计算最优值时得到地信息，以递归方法构造一个最优解； 4 贪心算法1、贪心算法的基本思想： ① 适用于求解最优化问题的算法往往包含一些列步骤，每一步都有一组选择； ② 贪心算法总是做出在当前看来是最好的选择； ③ 贪心算法并不从整体最优上加以考虑，它所做出的选择只是在某种意义上的局部最优选择； ④ 贪心算法不能对所有问题都得到整体最优解，但对许多问题它能产生整体最优解； ⑤ 在一些情况下，即使贪心算法不能得到整体最优解，其最终结果是对最优解很好的近似； ⑥ 与动态规划相比，贪心算法更简单，更直接； 2、活动安排问题： 目标：要在所给的活动集合中选出最大的相容活动子集合，尽可能多的活动； 复杂度分析：如果已经排序，算法的时间复杂度为Θ(n),如果事先没有按照结束时间增序排列，排序需O(nlgn) 贪心算法可以获得该问题的整体最优解。证明：①活动安排问题有一个最优解以贪心选择开始；②做出贪心选择之后，原问题简化为比原问题更小的但与原问题形式相同的子问题。 3、贪心算法的基本要素： ① 贪心算法通过做出一系列的选择来给出某一问题的最优解。它所作出的每一个选择当前状态下的最好选择(局部)，即贪心选择； ② 这种贪心选择并不总能产生最优解，但对于一些问题，比如活动安排问题，可以给出最优解； ③ 许多可以用贪心算法求解的问题，具备以下两个性质：(1) 贪心选择性质；(2) 最优子结构性质； 4、设计贪心算法的步骤： ① 将最优化问题转化，先做出选择，再解决剩下的一个子问题； ② 证明原问题总有一个最优解是做贪心选择得到的，从而说明贪心选择的安全； ③ 说明在做出贪心选择之后，子问题的最优解与所做出的贪心选择联合起来，可以得出原问题的一个最优解； 5、贪心选择性质： ① 是指所求问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来达到； ② 这是贪心算法可行的第一个基本要素，也是贪心算法与动态规划算法的主要区别； ③ 动态规划通常以自底向上的方式求解各个子问题； ④ 贪心算法则通常以自顶向下的方式进行，以迭代的方式做出 相继的贪心选择，没做一次贪心选择就将所求问题简化为规模更小的子问题； 6、最优子结构性质： ① 当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质； ② 问题的最优子结构性质是该问题可用动态规划算法或贪心算法求解的关键特征； 7、最优装载问题： ① 最优装载问题可用贪心算法求解； ② 采用重量最轻者先装的贪心选择策略，可产生最优装载问题的最优解； 8、贪心算法的重要实例： (1) 单源最短路径——Dijkstra算法 求某一点到所有其他各顶点的最短路长度； 设u是G的某一个顶点，把从源到u且中间只经过S中顶点的路称为从源到u的特殊路径，并用数组dist记录当前每个顶点所对应的最短特殊路径长度。 因为Dijkstra算法总是在V-S中选择”最近”(具有最短特殊路径长度)的顶点，所以说Dijkstra算法使用了贪心策略。 贪心策略体现在对V-S中的点的选择上。 对于具有n个顶点和e条边的带权有向图，如果用带权邻接矩阵表示这个图，O(n2) (2) 最小生成树 在G的所有生成树中，耗费最小的生成树称为G的最小生成树。 网络中的最小生成树在实际中有广泛的应用，最小生成树给出了建立通信网络的最经济的方案。 ① Prim算法 O(n2) ② Kruskal算法 从小到大排序，依次选择，判无环路； 贪心策略：将图中的边按权值从小到大排序，由小到大顺序选取各条边，若选某边后不形成回路，将将其保留作为输的一条边。 (3) Huffman编码 一种可变长编码，广泛应用于数据文件的压缩； Huffman算法以自底向上的方式构造表示最优前缀码的二叉树T。 贪心策略：每次都选择根节点”频率”值最小的两棵树合并。 5 随机算法1、随机数： 概率相等(均匀随机)，不可预测，不可重现； 在目前的计算机中，无法产生真正的随机数，因此在随机算法中使用随机数都是一定程度上随机的，即伪随机数。产生为随机数的方法：线性同余法； 2、确定性算法： 若输入确定，则对这个特定的输入的每次的运行过程是可重复的，运行结果是一样的； 3、随机算法的基本思想： ① 引入了随机因素； ② 在随机算法中，不要求算法对所有可能的输入均正确计算，只要求出现错误的可能性小到可以忽略的程度； ③ 另外，也不要求对同一输入，算法每次执行时给出相同的结果； 4、随机算法的特点： 有不少问题，目前只有效率很差的确定性求解算法，但用随机算法取求解，可以很快的获得相当可信的结果； 5、随机算法的应用领域： 随机算法在分布式计算、通信、信息检索、计算几何、密码学等许多领域都有着广泛的应用； 最著名的是在公开密钥体系，RSA算法方面的应用。 6、随机算法的分类： 通常分为两类：Las Vegas算法和Monte Carlo算法 (1) Las Vegas算法： 在少数应用中，可能出现求不出解的情况，但一旦找到一个解，这个解一定是正确的，在求不出解时，需再次调用算法进行计算，直到获得解为止，对于此类算法，主要是分析算法的时间复杂度的期望值，以及调用一次产生失败(求不出解)的概率。 (2) Monte Carlo算法： 通常不能保证计算出来的结果总是正确的，一般只能断定所给解的正确性不小于p(1/2&lt;p&lt;1); 通过算法的反复执行(即以增大算法的执行时间为代价)，能够使发生错误的概率小到可以忽略的程度； 由于每次执行的算法是独立地，故k次执行均发生错误的概率为(1-p)^k; 对于判定问题(只能回答”yes”或”no”)，带双错的：回答”yes”或”no”都可能错； 带单错的，只有一种回答可能错； Las Vegas算法可以看成是单错概率为0的Monte Carlo算法； 7、两类随机算法的应用场景： 使用时，选择哪一类随机算法，到底哪一种随机算法好呢？依赖于应用。 在不允许发生错误的应用中(人造飞船、电网控制等)，Monte Carlo算法不可以使用； 若小概率的出错允许的话，Monte Carlo算法比Las Vegas算法要节省许多时间，是人们常常采用的方法； 8、随机算法的优点： ① 对于某一给定的问题，随机算法所需的时间与空间复杂性，往往比当前已知的、最好的确定性算法要好； ② 到目前为止设计出来的各种随机算法，无论是从理解上还是实现上，都是极为简单的； ③ 随机算法避免了去构造最坏情况的例子； 9、找第k小元素的随机算法(Las Vegas算法)： 在n个数中随机找一个数A[i]=x,然后将其余n-1个数与x比较，分别放入三个数组中：S1(元素均&lt;x)、S2(元素均=x)、S3(元素均&gt;x) 若|S1|&gt;=k,则调用Select(k,S1); 若(|S1|+|S2|)&gt;=k,则第k小元素就是x; 否则就有(|S1|+|S2|)&lt;k,此时调用Select(k-|S1|-|S2|,S3) 定理：若以等概率方法在n个数中随机取数，则该算法用到的比较数的期望值不超过4n; 说明：如果假定n个数互不相同，如果有相同的数的话，落在S2中的可能性会更大，比较数的期望值会更小一些； 10、Sherwood随机化方法：(属Las Vega算法)： 如果某个问题已经有了一个平均情况下较好的确定性算法，但是该算法在最坏情况下效率不高，此时引入一个随机数发生器，可将一个确定性算法，改成随机算法，使得对于任何输入实例，该算法在概率意义下都有很好的性能（Select、Quicksort） 如果算法(所给的确定性算法)无法直接使用Sherwood方法，则可以采用随机预处理的方法，使得输入对象服从均匀分布(或者其他分布)，然后再用确定性算法对其进行处理。所得效果在概率意义下与Sherwood型算法相同。 Sherwood算法总能求得问题的一个解，且所求得的解是正确的； 当一个确定性算法在最坏情况和平均情况下的时间复杂度有较大差别时，可在确定性算法中引入随机性将其改造成Sherwood算法，以消除或减少问题的好坏输入实例间的差别。 11、Testing String Equality: 设A处有一个长字符串x，B处也有一个长字符串y，A将x发给B，由B判断是否由x=y; ① 首先由A发一个x的长度给B，若长度不等，则x≠y; ② 若长度相等，则采用“取指纹”的方法； A对x进行处理，取出x的“指纹”，然后将x的指纹发给B；由B检查x的指纹是否等于y的指纹；若取k次指纹(每次取法不同),每次两者结果均相同，则认为x与y是相等的；随着k的增大，误判率可趋于0； 常用的指纹： 令I(x)是x的编码，取Ip(x)=I(x)(mod p)作为x的指纹； 这里的p是一个小于M的素数，M可根据具体需要调整； 12、Pattern Matching(Monte Carlo算法) 给定两个字符串，X=x1,x2,…,xn,Y=y1,y2,…,ym,判断Y是否为X中的一段； ① 可用KMP算法在O(m+n)时间内获得结果，但算法较为繁琐。 ② 考虑用随机算法，暴力求解； 记X(j)=xj xj+1 … xj+m-1(从X的第j位开始，长度与Y一样的子串) 从起始位置j=1开始到j=n-m+1,逐一比较X(j)的指纹Ip(X(j))与Y的指纹Ip(Y) 由于Ip(X(j+1))可以很方便地根据Ip(X(j))计算出来，故算法可以很快完成； 最终算法复杂度为O(m+n) 该算法可以改造成Las Vegas算法，在Ip(Y)=Ip(X(j))时，不直接return j,而去比较Y和X(j) 13、Random Sampling问题 从n个元素中随机取m个数 Las Vegas算法，用一个长为n的布尔数组B来标识i是否被选中；初始时均表为“未选中”；然后随机产生[1,n]之间的一个整数，若B[i]为“未选中”，则将i加入被选中队列，同时把B[i]标识为“已选中”；反复执行，直到m个不同的数全部被选出为止； 上述算法存在问题，当n和m比较接近的时候，产生最后几个随机数的时间可能很长(有95%以上的可能性是已选中的数)， 改进方法：当m&gt;n/2时，先去生成(n-m)(&lt;n/2)个随机数，然后再取剩下的m个数作为选出的数； 上述算法存在的问题：① 当n与m相比大很多时(n&gt;m2)，布尔数组对空间浪费很多； 改进：用一个允许冲突的、长为m的散列表来存放随机数；产生一个数后，看其是否在散列表中，若不在则加入，若已在则抛弃该数，再去产生下一个数； 时间复杂度T(n)=Θ(n) 14、主元素问题 n个元素的数组中，某一元素个数超过一半，则该元素称为主元素； 对于给定数组T，判断T数组是否含有主元素； Mente Carlo算法： 每次随机选一个数，判断其在数组中是否存在； 计算时间和调用次数相关； 15、素数测试问题 判断一个数是否是是素数； 费尔马小定理：若n为素数，且0&lt;a&lt;n，有a^(n-1) mod n=1,即Fermat条件a^(n-1) mod n≠1则必为合数； 逆定理不成立，但反例不多，特别是当n很大且是随机选取的时候； 16、素数判定方法 直接用Fermat条件2^(n-1) mod n =1来判断n是否为素数； 此时，若算法的回答是“合数”，则100%正确； 若算法的回答是“素数”，则出错的概率很小（带单错）; 当n不太大时，满足条件2^(n-1) mod n =1的合数n不多; 能否对其他的a取测试是否有a^(n-1) mod n =1,从而再排除一些满足条件2^(n-1) mod n =1的合数； 回答是：可以排除一些，但不能完全排除； 满足Fermat条件的数未必全是素数； 有些合数也满足Fermat条件，这些合数被称为Carmichael数； 二次探测定理：如果p是一个素数，且0&lt;x&lt;p,则方程x^2 mod p = 1的解为x=1,p-1 利用二次探测定理，可以在基于Fermat条件判断时，增加二次探测，一旦违背二次探测条件，则可得出不是素数的结论。 17、n后问题 对于n后问题的任何一个解而言，每一个皇后在棋盘上的位置无任何规律，不具有系统性，而更像是随机放置的； Las Vegas算法： 在棋盘上相继的各行中随机地放置皇后，并注意使新放置的皇后与已放置的皇后互不攻击，直至n个皇后均已相容的放置好，或已没有下一个皇后的可放置位置时为止。 如果将上述随机放置策略与回溯法相结合，可能会获得更好的效果。 可以现在棋盘上的若干行中随机地放置皇后； 然后在后继行中用回溯法继续放置，直至找到一个解或宣告失败； 随机放置的皇后越多，后继回溯搜索所需的时间就越少，但失败的概率也就越大 n后问题变为针对8皇后问题： 随机放两个皇后，再回溯比完全用回溯快大约两倍； 随机放三个皇后，再回溯比完全用回溯快大约一倍； 随机放所有皇后，再回溯比完全用回溯慢大约一倍； 主要由产生随机数所需的时间导致。 6 回溯法图的表示——邻接表和邻接矩阵； 广度优先搜索（BFS） 深度优先搜索（DFS）尽可能深的搜索一个图 1、回溯法：有许多问题，当需要找出它的解集或者要求在某些约束条件下的最优解时，往往可以用回溯法； 回溯法的基本做法是搜索，他是一只可以避免不必要搜索的穷举式搜索法， 回溯法用于求解一些组合数较大的问题； 2、回溯法的基本思想： 回溯法在问题的解空间树中，按深度优先策略，从根节点出发搜索解空间树； 算法搜索至解空间树的任意一点时，先判断该节点是否包含问题的解； 如果肯定不包含，则跳过对该节点为根的子树的搜索，逐层向其祖先节点回溯； 否则，进入该子树，继续按深度优先策略搜索； 3、问题的解空间： 问题的解向量：回溯法希望一个问题的解能够表示成一个n元式(x1,x2,…,xn)的形式； 显约束：对分量xi的取值限定； 隐约束：为满足问题的解而对不同分量之间施加的约束； 解空间：对于问题的一个实例，解向量满足显式约束条件的所有多元组，构成了该实例的一个解空间； 通常将解空间组织成树或者图的形式； 问题的解空间一般用解空间树的方式组织； 树的根节点位于第一层，表示搜索的初试状态； 第二层的节点表示对解向量的第一个分量做出选择后达到的状态； 第一层到第二层的边上标出对第一个分量选择的结果； 依次类推，从树的根节点到叶子结点的路径就构成了解空间的一个可能解； 4、生成问题状态的说明： 扩展节点：一个正在产生儿子的节点被称为扩展节点； 活节点：一个自身已生成但其儿子还没有全部生成的节点称作活节点； 死节点：一个所有儿子已经产生的节点称作死节点； 生成问题状态的基本方法——DFS 生成问题状态的基本方法——回溯法 为了避免生成那些不可能产生最优解的问题状态，要不断利用限界函数处死那些不可能产生所需解的活节点，从而减少问题的计算量； 具有限界函数的深度优先生成法称为回溯法。 5、回溯法的基本思想： (1) 针对所给问题，定义问题的解空间； 复杂问题常有很多可能解，这些解构成解空间，确定正确的解空间很重要。 (2) 确定易于搜索的解空间结构； (3) 以深度优先方式搜索解空间，并在搜索过程中用剪枝避免无效搜索； (4) 常用剪枝函数：用约束函数在扩展节点处减去不满足约束的子树，用限界函数减去得不到最优解的子树； 在搜索至树上任意一点时，先判断该节点对应部分解是否满足约束条件，或是否超出目标函数的界： 判断该节点是否包含问题的(最优)解： 不包含，则跳过对以该节点为根的子树的搜索，剪枝； 包含，则进入以该节点为根的子树，继续按深度优先搜索； 回溯法的搜索过程涉及的节点(搜索空间)只是整个解空间树的一部分，搜索时，常用两种策略避免无效搜索(剪枝函数) 用约束条件减去得不到可行解的子树； 用目标函数减去得不到最优解的子树； 用回溯法解题的一个显著特征是在搜索过程中动态产生问题的解空间。在任何时刻，算法只保存从根节点到当前扩展节点的路径。 回溯法对解空间作深度优先搜索，因此，在一般情况下用递归方法实现回溯法。 采用树的非递归深度优先遍历算法，可将回溯法表示为一个非递归迭代过程。 6、回溯法求解时常见的两类解空间树： (1) 子集树：当所给问题是从n个元素的集合S中找出S满足某种性质的子集时，相应的解空间树称为子集树；O(2^n) (2) 排列树：当所给问题是确定n个元素满足某种性质的排列时，相应的解空间树称为排列树；O(n!) 7、装载问题：（子集树） 8、批处理作业调度： 批处理作业调度问题要求对于给定的n个作业，制定最佳作业调度方案，使其完成时间和达到最小。 9、符号三角形：O(n2^n) 10、n后问题： 11、0-1背包：（子集树） 12、图的m着色问题：优化问题、O(nm^n) 给定无向图G和m中不同颜色，用这些颜色为图G的各顶点着色，每个顶点着一种颜色。是否有一种着色方法使G中每条边的2个顶点着不同的颜色？ 可行性约束函数：顶点i与已着色的相邻顶点颜色不重复； 问题的解空间：高度为n+1的完全m叉树 13、旅行售货员问题：O(n!) （排列树） 14、圆排列问题：O((n+1)!) 给定一个大小不等的圆c1,c2,…,cn,现要将这n个圆排进一个矩形框中，且要求各圆与矩形框相切。 圆排列问题要求从n个圆的所有排列中找出最小长度的圆排列； 7 分支限界法1、分支限界法和回溯法的异同： ① 分支限界法类似于回溯法，是在问题的解空间树上搜索问题解的算法； ② 回溯法的求解目标是找出解空间树中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解； 搜索方式不同：回溯法以深度优先的方式搜索解空间树，而分支限界法以广度优先或以最小耗费优先的方式搜索解空间树。 2、分支限界法的基本思想： 分支限界法以广度优先或最小耗费优先的方式搜索问题的解空间树。 在分支限界法中，每一个活节点只有一次机会成为扩展节点。活节点一旦成为扩展节点，就一次性产生其所有儿子节点。在这些儿子节点中，导致不可行解或导致非最优解的儿子节点被舍弃，其余儿子节点被加入或节点列表中。 此后，从活节点表中取下一个节点成为当前扩展节点，并重复上述节点扩展过程。这个过程一直持续到找到所需的解或活节点表为空时为止。 3、常见的两种分支限界法：(1) 队列式(FIFO)分支限界法：按照队列先进先出(FIFO)原则选取下一个节点为扩展节点； (2) 优先队列式分支限界法：按照优先队列中规定的优先级选取优先级最高的节点成为当前的扩展节点； 应用优先队列式分支限界法求解具体问题时，应该根据具体问题的特点确定选用最大优先队列或者最小优先队列或者最小优先队列表示解空间的活节点表； 4、装载问题： 如果一个给定装载问题有解，则采用下面的策略可得到最优装载方案； 首先将第一艘轮船尽可能装满，将剩余的集装箱装上第二艘轮船； 优先队列式分支限界法：解装载问题的优先队列式分支限界法用最大优先队列存储活节点表。活节点x在优先队列中的优先级定义为从根节点到节点x的路径所相应的载重量再加上剩余集装箱的重量之和； 优先队列中优先级最大的活节点称为下一个扩展节点，以节点x为根的子树中所有节点相应的路径的载重量不超过它的优先级。子集树中叶节点所相应的载重量与其优先级相同。 在优先队列式分支限界法中，一旦有一个叶节点称为当前扩展节点，则可以断言该叶节点所相应的解即为最优解，此时可终止算法。 5、0-1售货问题： 6、旅行售货员问题：排列树 8 NP完全理论对于N个盘子的问题，如果使用递归进行求解，需要2^n-1次移动； 多项式时间：排序：O(nlgn)、有序查找：O(lgn)、最大、最小元：O(n)； 非多项式时间：旅行商问题：O(n^2 2^n)、背包问题：O(2^(n/2))； 将计算问题转化成语言 复杂性的度量，耗费的时间，耗费的存储。 1、计算的模型——自动机理论： ① 有限自动机(FA):存储量极小的计算机，在文本处理，编译程序及硬件设计中有应用； ② 下推自动机(PDA):带有一个栈的计算机，在程序设计语言和人工智能中有应用； ③ 图灵机(TM):有无限可改写存储的计算机，能解决实际计算机可以解决的一切问题； FA和FDA是简化的图灵机，一般以图灵机作为计算的理论模型； 2、P与NP问题是否相等： P问题是容易解决的问题，NP问题是容易验证的问题，P是属于NP的，但是严格相等还是真包含我们不得而知，他是21世纪最大难题，主要应用在密码学，解码和编码； 3、计算模型： 计算模型是计算机科学的重要组成部分； NPC的原始定义需要借助非确定性图灵机等计算模型的概念； 计算模型中有不少好的思想可供借鉴； RAM、RASP、确定性Turing机、非确定性Turing机 (1) 一个RAM程序定义了输入带到输出带的一个映射； (2) RASP的整体结构类似于RAM，所不同的是RASP的程序是存储在寄存器中的。 (3) 凡是Turing机可以计算的问题就是可计算的，否则就是不可计算的。 任何合理的计算模型都是相互等价的(计算范围相同)； 合理：单位时间内可以完成的工作量，有一个多项式的上限； 与RAM模型类似，图灵机既可以作为语言接收器，也可作为计算函数的装置； 4、非确定性Turing机： 一般来说，将可由多项式时间算法求解的问题看做是易处理的问题，而将需要超多项式时间才能求解的问题看做是难处理的问题； 在非确定性图灵机计算模型(NDTM)下，许多问题可以在多项式时间内求解； 5、P类与NP类语言： P：能在多项式时间内被一台图灵机所接受的语言； NP：能在多项式时间内被一台NDTM所接受的语言； NPC：属于NP问题中比较难解的问题； 6、最优化问题和判定问题： 判定问题：回答”yes”或”no”; 最优化问题：可以与一个判定问题相对应； 7、证书： 若集合S包含判定问题A的所有解，则称S是A的证书集，S中的元素称为A的一个证书（注意，证书不一定是解）; Hamilton路径问题： 给定无向图G=(V,E),任何一个由n个互不相同的顶点构成的序列就是H路径问题的一个证书； 如果图G有Hamilton路径，则该路径一定属于S； 8、P类问题和NP类问题： NP类问题是多项式时间可验证的；P类问题是多项式时间可解的； Hamilton路径问题的验证：对于任给的一个证书即序列，只要逐一检查序列中相邻点之间是否有边相连； 若n-1个相邻点对均有边相连，则该序列是Hamilton路径，否则不是； 验证算法时间为Θ(n),故是多项式时间可验证的； NP完全问题是难处理的，迄今为止，未发现有NP完全问题的多项式时间求解方案； 9、规约： 设IA是判定问题A的任一个实例，B是另一判定问题，若存在一个从A到B的映射f满足一定条件，则称问题A可多项式变换为B，记作A≤pB(≤p亦称Karp规约) 若A≤pB且问题B是多项式时间可判定的，则问题A也一定是多项式时间可判定的； 10、NP完全问题的实例： (1) k-团问题 (2) 顶点覆盖： ① 最优化问题：在一个无向图G中，找一个顶点数最少的顶点集，满足：任一条边的两个顶点中至少有一个在此集合中； ② 判定问题：无向图G中是否存在顶点数为k的顶点覆盖； (3) 子集和问题： (4) 限制法： (5) 背包问题： 11、NP-hard类问题的求解方法： (1) 当n不太大时，可使用①动态规划法，②分支限界法，③回溯法 (2) 求近似解，在误差允许范围内找一个解，该近似解可以在多项式时间里得到； (3) 用启发式算法求解，根据具体问题设计启发式搜素策略，在理论上往往缺乏严格证明，用实验数据说明算法很有效； (4) 只能优化算法，常常能获得很好的结果，但有偶然性，与最优解的误差难以给出； 9 近似算法所有的NP完全问题，均未能找到多项式时间的算法，故当问题规模较大时，求得最优的精确解的可能性很小； 在此情况下，往往退而去求比最优精确解稍差一点的解作为问题的近似答案； 1、近似算法的性能： 近似算法一般都比较简单，但设计近似算法时必须关注所设计的算法得到的近似解与最优解之间的差距到底有多大； 2、近似方案： 常数近似比的近似算法 多项式时间近似方案 完全多项式时间近似方案 3、装箱问题：(bin packing) (1) First-Fit(FF)算法 从排在最前面的箱子开始，对每个箱子剩余体积逐一进行检查，一旦碰到第一个能够装进当前物体的箱子时，就立即把这个物体装进箱子。对每个物体反复执行上述过程。 算法的最坏时间复杂度为O(n^2) 用FF算法不能保证所获得的解是最优解。 (2) Next-Fit(NF)算法 先把第一个空箱置为当前箱。然后依次把物品装箱，若当前箱放的下则放，否则放入下一个箱子，并指向下一个箱子。 算法的最坏复杂度为O(n),因为对每个物品只检查当前的箱子。 (3) Best-Fit(BF)算法 FF算法的修改，在已装有物品的箱子中，找一个既能放下ui,又能使其剩余空间最小的箱子来放ui。 BF算法在最坏情况下本质上和FF相同。 (4) First-Fit Decreasing(FFD)算法 先将所有物品从大到小排序，然后再使用FF法 4、顶点覆盖问题： 顶点覆盖问题就是要求在一个给定的无向图中，找出一个就有最小规模的顶点覆盖 5、旅行商问题： 旅行商问题(TSP)简单描述： 给定一个完全无向图G=(V, E),其每一边(u,v)属于E有一非负整数代价u(u,v) 要找出G中具有最小代价的哈密尔顿回路； TSP的特殊性质： 代价函数c往往具有三角不等式性质，即对任意的3个顶点u,v,w属于V，有c(u,w)≤c(u,v)+c(v,w) 当图G中的顶点就是平面上的点，任意2顶点间的代价就是这2点间的欧氏距离时，代价函数c就具有三角不等式性质。","categories":[{"name":"notebook","slug":"notebook","permalink":"http://cheertt.top/categories/notebook/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://cheertt.top/tags/笔记/"},{"name":"算法","slug":"算法","permalink":"http://cheertt.top/tags/算法/"}],"keywords":[{"name":"notebook","slug":"notebook","permalink":"http://cheertt.top/categories/notebook/"}]},{"title":"彭明辉-研究生手册","slug":"彭明辉-研究生手册","date":"2019-07-28T00:45:54.115Z","updated":"2019-08-01T12:12:53.400Z","comments":true,"path":"p/46253.html","link":"","permalink":"http://cheertt.top/p/46253.html","excerpt":"","text":"我是在研一暑假这个阶段看到的彭明辉教授的研究生手册，在研究生的这个阶段，看这个可谓是再适合不过。自己研究方向的相关论文已经看了大半年，已经到了快准备毕业论文开题答辩的节点，这本书让我提前了解写论文过程中的每个阶段，以及会经历的一些细节。 下面是我在阅读过程中，从书中摘录的一些极大触动我的句子。判断一本书是否有价值，在人生所处阶段以及人生经历是分不开的，所以大佬们推荐的书单固然有其理由，但永远需要明确的是，符合当前自己需求的书才是最适合自己的书。 1 达摩面壁，慧可立雪九成的力气爬到巨人得肩膀上，一成的力气用在活用。 解决问题最快、最省钱且风险最小的办法就是抄袭既有，而非创新。研究的方法与目的就是为问题寻找正确的或较可靠的答案，或者为问题找到更好的解决方案。这一套方法与程序可以用来解决产业界、政府机构和学术界的问题，也可以用来解决人生中的其他关键问题。 研究的过程始于文献回顾，创意是用来走完最后一里路。先从文献回顾去了解前人的失败经验和教训，避免重蹈覆辙，藉此降低风险；接着吸收前人的智慧，站在巨人的肩膀上，先立于不败之地；最后才是分析既有答案的缺点与不足，用自己的创意（聪明和运气）想出改进的办法，以便推陈出新。 2 黄金与粪土——学术著作的要件学位论文的第一要件是原创新或新颖性，整本论文都是为了要报告过去学术界尚未发现的事情或者推翻、修正过去学术界普遍相信的事件或。学位论文的第二要见是严谨性与客观性。 学术研究的核心能力：创新的能力、自我批判的能力、文献回顾的能力。 学术圈始终在追求真理，以及摆脱一切因为时间、空间、文化或个人特质而造成的主观、偏见，并且一直都在企图通过演绎方法将知识条理化或系统化。 一般硕士训练的重点在于文献回顾和自我批判的能力，对论文的原创新不高，略有所成即可。 学术论文必须兼具7项要见：（1）原创性；（2）可靠的证据支持；（3）批判性的检视过程里；（4）理论性、系统性与一致性；（5）客观性与可重复性；（6）根学术界的明确关系与对话；（7）清晰的文采与叙述。学术研究的核心能力有三项：创新的能力、批判性思考以及文献回顾能力，其中批判性思考必须与领域内知识紧密结合。为了培养出这三种能力，你需要负责的指导教授、好的学习环境和认真的学习过程。 3 山中无厉日，寒尽不知年——研究的历程和时间表寻找跟主题相关的关键词，搜索相关论文，替升自己的文献检索能力。勾勒出学术界研究这个问题所采用的所有方法，以及这些方法背后的原因与机制。创新，最简单的方法就是，取长补短，糅合 研究过程中第一大阶段性目标既有学术论文中的共识与争论以及各个流派的大致特色与优缺点；研究过程中第二大阶段性目标提出创新的策略与研究构想，并且完成可行性的评估与完整的文献回顾；研究过程中第三大阶段性目标完成理论发展，整合各种论据，反复检验与论证假说中的答案或解决方案，并且据以调整假说、假设条件与适用范围，直到有足够的贡献以及找不到弱点为止。论文品质的真正差别往往不在于他们最后的答案，而是在于他们回答的方式和论据有多严谨、可靠——最著名的论文不必然是最富有创意的，但一定是最严谨而让人不得不信服的。 4 恩师与廉价劳工——指导教授与研究能力的养成批判性思考的6种能力：（1）分析论证、概念、方法和问题脉络的能力；（2）评估论据、方法、结果的价值和可靠性等；（3）对各种论据与事实进行完整的演绎与归纳等推理，以产出新的结论或命题、发现；（4）解释各种论据的内在关系或可能的因果连结，以形成规律或理论；（5）诠释与解释各种论据、概念、理论与研究结果的内在内涵和可能衍生的影响、重要性与价值等；（6）有能力自行引导与组织自己的思考活动，以便选择研究方法，规则研究活动，寻找论据，从论据产出可靠的结论或判断，并且在这过程中侦测出自己隐藏的假设或前提，跳跃的推断等错误；指导教授的责任是培育你自己解决问题的能力，而不是替你解决问题。 5 万绿丛中一点儿红——研究主题与论文题目的关系每一种研究主题都包含非常多样的论文题目，足以满足各种不同的兴趣和专长，可以适合每一个人的特质和兴趣。因此，最好是尽快决定研究主题，以便有较多的时间去决定论文题目。 6 告别大学时代——期刊论文的阅读服务螺旋式阅读法——最自然最省力的方法。第一次阅读论文时，最主要聚焦在三个最容易回答的问题：（1）这篇论文想解决什么问题？最适合描述该问题的术语是什么？（2）它使用的方法是什么？学术界如何称呼他？（3）前述的问题和方法属于哪一个学术领域？回答上述三个问题，主要到论文的题目、摘要和引言中寻找答案。 千万别爬峭壁——读懂一篇期刊论文的多种途径。阅读期刊论文不应该以论文为中心，而要以问题为中心。第一次阅读的时候，只想办法读懂最粗浅、易懂的部分，藉此判断你所需要的其他背景知识，并且找到相关的科普级文件阅读，以提升背景知识。第二次阅读时，设法确定这篇论文所属的学术领域、使用的方法，想解决的问题，以及最适合用来描述他们的学术领域、使用的方法，想解决的问题，以及适合用来描述他们的学术术语，然后找出相关的入门级学术文件来阅读，进一步提升背景知识。第三次阅读后应该可以读懂论文的一两层，你可以据此去找出跟这论文主题或方法较接近易读的书或硕博士论文，找出书中较密切相关的章节、页码和段落，不吃力的读过一次，藉此增加较深入的专业知识。第四次阅读后可能读懂论文的三四层，然后去粗略读过这一片论文后面的参考文献，找到有助于你进一步理解原来期刊论文的段落，并读完他们。第五次阅读后可能可以读懂七八层，且有能力研判自己欠缺的其他背景知识。然后，你上网找出对你有用的论文、报告，只挑对你有用的章节阅读，再加上自己的分析理解与推理能力，以便把论文最后的部分读懂与想通。 7 鸟瞰全局——总览式文献回顾与田野文献回顾的第一步是鸟瞰全局，找到最有机会突破的研究焦点或研究子题，同时试着回答以下问题：（1）这个研究的焦点与哪些研究字题相关？如何关联？（2）在这个研究焦点和各种相关研究子题上，有过哪些主要的研究角度？哪些主要的主张和流派？（3）这些角度、主张与流派各有何优缺点？他们各自举出过哪些有利于自己的论据？彼此举出过哪些不利于对方的论据？（4）你对于这个研究焦点有何想法？既有论据有哪些是支持你的想法？有哪些论据可能不利于你的想法？（5）假如你试着调整对这个研究焦点的看法，有没有机会找到更多论据来支持自己的想法？还是可以反过来找到其他竞争者的弱点，来强化自己的主张？ 鸟瞰全局的利器——总览式文献回顾与回顾型论文简介。学术界的论文主要可以分为两大类，第一类是针对新的问题，提出原创性的新理论、新论据或新的解决方案，这类论文明确聚焦在一个范围很小的研究子题上，以及跟这个小范围的研究子题有关的文献；第二类是回顾型论文，它旨在从鸟瞰的角度，介绍一个研究主题内的各种既有的研究成果与现状 研究工作与文献回顾的第一步，是利用回顾型论文了解一个研究生主题的梗概，包括问题背景与学术研究的起源，主要的发展历程、研究子题的相互关联、各种观点与流派，重要的代表著作与研究成果，各家各派的主要争论与共识，以及最新的研究课题和发展趋势。文献回顾的目的，并非知识消极地吸收文献中地知识并加以整理，而是为了要回答你自己所提出来地问题（疑点或假说）以及激励进一步地思考与创意。好的研究程序应该是由粗而细且由浅而深地发问、阅读与思考，因此在决定研究题目之前，没必要仔细揣摩任何难懂地原创性期刊论文。 8 众里寻他千百度——论文题目与研究范围研究题目的两种基本类型是为问题寻找正确的答案，或有效的解决方案。 9 青出于蓝——批判与创新的要领（上）决定论文题目和研究范围后，下一个工作就是文献回顾，目的就是回答两个问题：（1）在你拟定的论文题目和研究范围内，有哪些既有的答案或解决方案？既有知识的边界在哪里？（2）前述的既有答案中，有哪些确实可行而毋庸重复？哪些回答论据不足、观点偏颇 文献回顾有两大重要功能，其一是完善批判与检视的原则与要领，其二是通过文献回顾开发更多创新的想法。最后讲创意和批判原则合成一个严谨而有价值的研究设计。研究的创新主要有两种类型，以新的论据、观点或较严谨的方法重新探索旧的题目，而有新颖的发现；或者以既有的方法适度修改后，去探究新的研究领域、题目而造成的新的发现。 10 青出于蓝——批判与创新的要领（中）方法没有绝对的好坏，只有相对的优缺点——优点再多的方法如果用错了地方，就可能会一无是处，缺点再多的方法，如果用对了地方，也会可圈可点。所以，在于你有没有为给定的问题情境找到最适用的方法，而不在于哪个方法的优点较多。 11 青出于蓝——批判与创新的要领（下）制度设计是为了达成某些社会效益，或者解决某些社会弊端，抑或是提升企业的经营效率；它假设我们可以通过制度或政策工具来产出某些社会效益，或者缓抑某些不良的社会现象。因此，制度研究往往会牵涉到一些因果关系的研究。 12 上穷碧落下黄泉——十倍速文献回顾的方法文献回顾第一阶段的流程图（1）用关键字搜寻回顾习型论文，找出最相关的数十篇论文，略读摘要和引言，判断这些文献的相关性和派别。并根据论文后面的参考文献（2）细读各派论文的摘要和引言，标定该派特点的关键性论文；（3）初步确定问题特性表与方法流派，更新关键字，扩大搜寻范围；（4）锁定最相关的一派，略读个论文的论文主题，标定各论文最省力的阅读次序； 13 运筹帷幄——研究工作的策略、进展与风险在完成文献回顾并且产生各种研究的创意之后，接下来必须将他们发展成严谨的研究构想，评估其可行性，并且以备胎方案等手段进行风险控管。筛选、取舍研究创意或构想时，四个关键的原则是：（1）能否产出可被反复检视的确切结论；（2）能否整合成系统性成果，而非零碎的发现，从而提升其严谨度与学术价值；（3）优先评估、发展学术价值较高的论题；（4）避开风险过高或可行性太低的论题； 14 为山九仞——整并补强,巩固战果你的论文最主要的贡献是什么？这个问题可以被分为：你的论文有哪些新颖的贡献？其中最重要的是什么？什么才是好的论文回顾？论文的第一章，必须明确宣告论文的题目与研究的范围，在这个范围内的关键论文，你都必须读过。想要选出最有利的实验条件，就需要理论的预测与引导，或者至少要有言之成理的判断依据，而不能是想当然或碰运气。如果没有理论的引导，用地毯式搜索的方式去求证你要验证的现象，在学术界会被形容为粗暴的手段，因为，他经常是浪费时间与精力，以致事倍功半。 15 掷地有声——学位论文的写作要领每一篇学术论文都是企图向审查委员证明三件事：（1）这篇论文含有原创性的新知识、观点、方法，以有条不紊的方式呈现；（2）这些新颖的知识、观点、方法，对学术界的进步有不可忽视的贡献；（3）他们可以表述为有系统的客观知识，有充分的论据和理论支持，经得起该领域的专家的反复检视。 论文的主要内容就是你的答案或解决方案，他们的假设、前提与适用范围，从各种角度进行反复论证、释疑与答辩，支持这些论点所需要的论据，以及结论。至于那些不具有新颖性或无助于提升学术价值的研究过程、个人的心酸好饿等，都没有必要，甚至不应该写进去。一篇论文通常包含6个主要部分，依序为：摘要、导论或简介、主要理论、研究方法与研究架构、研究结果与分析、讨论与结论和参考文献。每一部分各司其职，严密的整合在一起，有其内在的关系和逻辑。摘要通常只有三五百字，分成二至三段，篇幅尽量在一页以内。你必须用最精准的措辞说出研究主题、研究范围、研究方法，研究的特色与主要的研究成果。 导论或简介 论文的第一章通常是导论或简介，大多分成三个小节，依序为：研究动机与问题背景、文献回顾，以及本研究论题、研究项目与研究成果（贡献）。在第一小节你必须清楚指出，本研究的主题与现实世界有何关系，以及它在学术界的重要性，以便据此彰显这个研究的必要性与价值。接着在第二小节必须回顾与这个研究主题有关的文献，以便据此彰显勾勒出既有知识的的优势与不足处，藉此说明这个研究非可有可无。最后在第三小节陈述你所完成的研究项目和主要成果，作为这一章的结束和结论。通过这样的论述过程，其实你在依次说服读者三件事：（1）第一节旨在宣告这个研究主题很重要；（2）第二节则是在宣告过去的文献确实在这个主题上有所斩获，并逐步扩大，深化成果，但是还留下一大片重要的问题，（3）第三节所描述的研究项目，刚好填补了这个文献的缺口，并且有具体的成果和贡献。 研究主题、项目与成果 文献回顾，先介绍一篇开山之作的主要成就和一项不足，而下一篇文献刚好利用一个新的技术或观点解决了这一项不足，并且留下了另一个关键的问题被第三篇文献用某种新的技术解决，一次类推直到最新的文献，而他所留下的问题刚好是你的研究所要解决的。这样的论述结构好学、好写，而且逻辑清晰、流畅，易读而不易误解——不重要的先谈，重要的留在后头。文献回顾不是流水账正确的论文写作顺序，通常是先从第二章开始写，依序写下去，写完最后一章的结论与建议之后，再回头写第一章，而摘要与论文名称则是留到最后再写。 16 终极秘笈——口试委员的期待（1）你为何要选择这个题目当硕士题目？你的研究动机是什么，陈述这个题目的学术价值或应用价值，自己的兴趣。（2）你如何将一个学术性的问题概念化成一个学术性的问题？你为什么采用采用这个观点、角度或理论模型，去探讨你的原始问题？你有没有想过其他的选择？你如何确定这个选择确实是合理的，甚至是最佳的？你为何选择这个研究范围，而不选择一个更大或更小的研究范围？（3）你是如何发展出这个研究架构？（4）你的研究架构合理吗？有没有任何牵强之处或弱点？（5）你为何要采取这个手段来取得所需要的论据？你为何使用某一种统计方法，而不使用另一种？（6）你如何选择样本，材料或研究范围？（7）你如何产出主要的结论？（8）要如何将你的发现进行更广泛地解读或应用？（9）你的研究对学术界有何贡献？（10）你对自己的研究成果有何意见（批评）？你对以后的研究有何建议？（11）你毕业后有何打算？（12）你还有什么话想说吗？ 硕、博士学位的八大核心能力：（1）创新的能力或对学术界的贡献，有人具体的称他为【知识的跨距】；（2）学术的严谨性与论述的一致性，包括论据拾取，分析、论证与解读过程所呈现的专业性与严谨度，以及论据失去与推论过程的一致性；（3）具有批判精神与策略性思考的方法论能力，包括形塑问题，设计研究架构，并且正确选择研究方法，从批判的角度自我质疑，并将所有的抉择合理化。（4）对于专业知识的掌握能力与理解能力，包括掌握相关文献且活用文献的能力；（5）在有审查的学术期刊或学术会议上，发表其研究结果的可能性，如果能附上已发表的著作清单会更好。（6）分析、批判与客观评价个人研究成果的能力。（7）论文的品质与著作权的理清；（8）口试的表现，尤其是回答问题过程中所展示的独立思考的能力，简洁而切中要点的回答和条理的清晰，以及伴随而来的自信； 17 终生受用——研究能力的活用与转化硕、博士学位的三大能力可以被分为三大部分：（1）主动取得并正确运用专业知识的能力；（2）自我批判与辨别是非的能力；（3）创新的能力；硕、博士真正的核心能力是：【探索未知、明辨是非、推陈出新】研究所得首要学习目标不是知识领域得扩充，而是阅读能力与思想屡次提升。","categories":[{"name":"booking","slug":"booking","permalink":"http://cheertt.top/categories/booking/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://cheertt.top/tags/工具/"}],"keywords":[{"name":"booking","slug":"booking","permalink":"http://cheertt.top/categories/booking/"}]}]}