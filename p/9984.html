<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="cheerttの个人博客">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="http://cheertt.top">
    <!--SEO-->

    <meta name="keywords" content="笔记 PyTorch">


    <meta name="description" content="0 简介本博客笔记主要根据 《深度学习框架PyTorch：入门与实践》 整理而来，知识要点不算详细，主要为了知识点框架的罗列。

1 PyTorch简介Tensorflow、PyTorch、MX...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>PyTorch入门实践 | cheerttの个人博客</title>


    <link rel="alternate" href="/atom.xml" title="cheerttの个人博客" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header" style="background-color:#e67e22;">

    
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://cheertt.top">cheerttの个人博客</a>
                </div>
		<div style="float:left; line-height: 2em; width:470px; height:50px; background-image:url('http://puj2izln4.bkt.clouddn.com/banner.jpg')">
		    
		
		</div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i><span style="font-size:16px;">首页</span></a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/AI/"><i class="fa "></i><span style="font-size:16px;">AI</span></a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/coding/"><i class="fa "></i><span style="font-size:16px;">Coding</span></a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/Algorithm/"><i class="fa "></i><span style="font-size:16px;">Algorithm</span></a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/notebook/"><i class="fa "></i><span style="font-size:16px;">笔记</span></a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/booking/"><i class="fa "></i><span style="font-size:16px;">读书</span></a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i><span style="font-size:16px;">时间轴</span></a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="PyTorch入门实践">
            
	            PyTorch入门实践
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/notebook/">notebook</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/笔记-PyTorch/">笔记 PyTorch</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/08/01</span>
        </span>
        
            <span class="fa-wrap">
                <i class="fa fa-eye"></i>
                <span id="busuanzi_value_page_pv"></span>
            </span>
        
    
</div>
            
            
    </div>
    
    <div class="post-body post-content">
        <h3 id="0-简介"><a href="#0-简介" class="headerlink" title="0 简介"></a>0 简介</h3><p>本博客笔记主要根据 <a href="https://github.com/chenyuntc/pytorch-book" target="_blank" rel="noopener">《深度学习框架PyTorch：入门与实践》</a> 整理而来，知识要点不算详细，主要为了知识点框架的罗列。</p>
<p><img src="http://puj2izln4.bkt.clouddn.com/notebook/pytorch.jpg" alt="cs231n-numpy"></p>
<h3 id="1-PyTorch简介"><a href="#1-PyTorch简介" class="headerlink" title="1 PyTorch简介"></a>1 PyTorch简介</h3><p>Tensorflow、PyTorch、MXNet 几乎所有的框架都是基于计算图的，而计算图又分为静态计算图和动态计算图。静态计算图先定义再运行(define and run)，一次定义多次运行，而动态计算图是在运行过程中被定义的，在运行时构建(define by run)，可以多次构建多次运行。PyTorch和Tensorflow都是基于计算图的深度学习框架，PyTorch使用的是动态图，而Tensorflow使用的是静态图。在PyTorch中每一次前向传播（每一次运行代码）都会创建一幅新的计算图。</p>
<p>静态图一旦创建就不能修改，而且静态图定义的时候，使用了特殊的语法，就像新学的一门语言。这还意味着你无法使用if、while、for-loop等常用的Python语句。因此静态图不得不为这些操作专门设计语法，同时在构件图的时候必须把所有可能出现的情况都包含进去，这也导致了静态图过于庞大，可能占用过高的显存。动态图框架就没有这个问题，它可以使用Python的if、while、for-loop等条件语句，最终创建的计算图取决于你执行的条件分支。</p>
<p>动态图的思想直观明了，更符合人的思考过程。动态图的方式使得我们可以任意修改前向传播，还可以随时查看变量的值。如果说静态图框架好比C++，每次运行都要编译才行(session.run)，那么动态图框架就是Python,动态执行，可以交互式查看修改。</p>
<p>动态图带来的另一个优势是调试更容易，在PyTorch中，代码报错的地方，往往就是你写错代码的地方，而静态图需要先根据你的代码生成Graph对象，然后在session.run()时报错，这种报错几乎很难找到对应的代码中真正的错误的地方。</p>
<p>PyTorch的设计遵循 tensor -&gt; variable(autograd) -&gt; nn.Module三个由低到高的抽象层次，分别代表高维数组(张量)、自动求导(变量)和神经网络(层/模块)，而且这三个抽象之间联系紧密，可以同时进行修改和操作。</p>
<h3 id="2-快速入门"><a href="#2-快速入门" class="headerlink" title="2 快速入门"></a>2 快速入门</h3><h4 id="2-1-Tensor"><a href="#2-1-Tensor" class="headerlink" title="2.1 Tensor"></a>2.1 Tensor</h4><p>函数名后面带下划线的函数会修改tensor本身。</p>
<p>tensor和numpy对象共享内存，所以它们之间的转换很快，而且几乎不消耗资源。</p>
<h4 id="2-2-autograd"><a href="#2-2-autograd" class="headerlink" title="2.2 autograd"></a>2.2 autograd</h4><p><code>autograd.Variable</code>是Autograd中的核心类，它简单封装了Tensor，并支持几乎所有Tensor的操作。Tensor被封装成Variable之后，可以调用它的<code>.backward</code>实现反向传播，自动计算所有梯度。</p>
<p>Variable主要包含三个属性：</p>
<ul>
<li>data: 保存Variable所包含的Tensor</li>
<li>grad: 保存data对应的梯度，grad也是个Variable，而不是tensor，他和data的形状一样</li>
<li>grad_fn: 指向一个Functions对象，这个Function用来反向传播计算输入的梯度</li>
</ul>
<p>grad在反向传播过程中是累加的，这意味着每次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。</p>
<p>Variable和Tensor具有近乎一致的接口，在实际使用中可以无缝切换。</p>
<h4 id="2-3-神经网络"><a href="#2-3-神经网络" class="headerlink" title="2.3 神经网络"></a>2.3 神经网络</h4><p><code>torch.nn</code>是专门为神经网络设计的模块化接口，nn构建于autograd之上，可以来定义和运行神经网络。可以把它看作一个网络的封装，包含网络各层定义及forward方法，调用forward(input)方法，可返回前向传播的结果。</p>
<p><strong>定义网络</strong></p>
<p>定义网络时，需要继承<code>nn.Module</code>，并实现它的<strong>forward</strong>方法，把网络中具有<strong>可学习参数</strong>的层放在构造函数<code>__init__</code>中。如果某一层（如ReLU）不具有可学习参数，则既可以放在构造函数中，也可以不放。另外，<code>nn.Module</code>子类的函数必须在构造函数中执行父类的构造函数。</p>
<p>只要在<code>nn.Module</code>的子类中定义了forward函数，backward函数就会被自动实现（利用autograd）。在forward函数中可使用任何Variable支持的函数，还可以使用if、for循环、print、log等Python语法。</p>
<p>网络的可学习参数通过<code>net.parameters()</code>返回，<code>net.named_parameters</code>可同时返回可学习的参数及名称。</p>
<p>forward函数的输入和输出都是Variable，只有Variable才具有自动求导的功能，Tensor是没有的，所以在输入时，需要把Tensor封装成Variable。</p>
<p><strong>损失函数</strong></p>
<p>nn实现了神经网络中大多数的损失函数。</p>
<p><strong>优化器</strong></p>
<p>在反向传播计算完所有参数的梯度后，还需要使用优化方法更新网络的权重</p>
<h4 id="2-4-数据加载与预处理"><a href="#2-4-数据加载与预处理" class="headerlink" title="2.4 数据加载与预处理"></a>2.4 数据加载与预处理</h4><p>torchvision实现了常用的图像数据加载功能，例如ImageNet、CIFAR10、MNIST等，以及常用的数据转换操作，方便数据加载。</p>
<p>Dataset对象是一个数据集，可按下标访问，返回形如（data, label）的数据。</p>
<p>DataLoader是一个可迭代对象，它将dataset返回的每一条数据样本拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，对DataLoader也完成了一次迭代。</p>
<h3 id="3-Tensor和autograd"><a href="#3-Tensor和autograd" class="headerlink" title="3 Tensor和autograd"></a>3 Tensor和autograd</h3><h4 id="3-1-Tensor"><a href="#3-1-Tensor" class="headerlink" title="3.1 Tensor"></a>3.1 Tensor</h4><p>从接口的角度将，对tensor的操作可分为两类：</p>
<ul>
<li><code>torch.function</code>，如<code>torch.save</code>等</li>
<li><code>tensor.function</code>，如<code>tensor.view</code>等</li>
</ul>
<p>为方便使用，对tensor的大部分操作同时支持这两个接口。如<code>torch.sum(a, b)</code>和<code>a.sum(b)</code>功能等价。</p>
<p>从存储角度讲，对tensor的操作又可以分为两类：</p>
<ul>
<li>不会修改自身的数据，如<code>a.add(b)</code>，加法的结果会返回一个新的tensor</li>
<li>会修改自身的数据，如<code>a.add_(b)</code>，加法的结果仍存储在a中，a被修改了</li>
</ul>
<p>函数以<code>_</code>结尾的都是inplace操作，即会修改调用者自己的数据，在实际应用中需加以区分。</p>
<p><code>t.Tensor(*sizes)</code>创建tensor时，系统不会马上分配空间，只会计算剩余的内存是否足够使用，使用到tensor时才会分配，而其他操作都是在创建完tensor后马上进行空间分配。</p>
<p><strong>常用tensor操作</strong></p>
<p>通过tensor.view方法可以调整tensor的形状，但必须保证调整前后元素总数一致。view不会修改自身的数据，返回的新tensor和源tensor共享内存。resize是另一种调整size的方法，但与view不同，它可以修改tensor的尺寸。</p>
<p><strong>内部结构</strong></p>
<p>tensor分为头信息区和存储区，信息区主要保存着tensor的形状（size）,步长（stride）,数据类型（type）等信息，而真正的数据则保存成连续数组。由于数据动辄成千上万，因此信息区元素占用内存较少，主要内存占用取决于tensor中元素的数目，即存储区的大小。</p>
<p><strong>向量化</strong></p>
<p>向量化计算是一种特殊的并行计算方式，一般程序在同一时间只执行一个操作方式，它可在同一时间执行多个操作，通常是对不同的数据执行同样的一个或一批指令，或者说把指令应用在一个数组/向量上。向量化可极大提高科学运算的效率。</p>
<ul>
<li>大多数<code>t.function</code>都有一个参数out，这时产生的结果将保存在out指定的tensor之中；</li>
<li><code>t.set_num_threads</code>可以设置PyTroch进行CPU多线程并行计算时所占用的线程数，用来限制PyTorch所占用的CPU数目；</li>
<li><code>t.set_printoptions</code>可以用来设置打印tensor时的数值精度和格式；</li>
</ul>
<h4 id="3-2-autograd"><a href="#3-2-autograd" class="headerlink" title="3.2 autograd"></a>3.2 autograd</h4><p><strong>Variable</strong></p>
<p>PyTorch在autograd模块中实现了计算图的相关功能，autograd中的核心数据结构是Variable。Variable封装了tensor，并记录对tensor的操作记录用来构建计算图。</p>
<p>Variable的构造函数需要传入tensor,同时有两个可选参数：</p>
<ul>
<li>data: 需要传入的tensor</li>
<li>requires_grad(bool): 是否需要对该Variable进行求导</li>
<li>volatile(bool): 意为“挥发”，设置为True,构建在该variable之上的图都不会自动求导，专为推理阶段设计</li>
</ul>
<p>PyTorch使用的是动态图，它的计算图在每次前向传播时都是从头开始构建的，所以它能够使用Python控制语句，根据需求创建计算图。这一点在自然语言处理领域很有用。</p>
<p>只有对variable的操作才能使用autograd，如果对variable的data直接进行操作，将无法使用反向传播。除了参数初始化，一般我们不会直接修改variable.data的值。</p>
<h3 id="4-神经网络工具箱nn"><a href="#4-神经网络工具箱nn" class="headerlink" title="4 神经网络工具箱nn"></a>4 神经网络工具箱nn</h3><p>将模型的所有参数转存到GPU上，<code>model = model.cuda()</code>上</p>
<p>将输入数据放置到GPU上，<code>input.cuda()</code></p>
<p>多个GPU并行计算</p>
<p><code>new_net = nn.DataParallel(net, device_ids=[0, 1])</code></p>
<p><code>output = new_net(input)</code></p>
<p><code>output = nn.parallel.data.parallel(net, input, device_ids=[0, 1])</code></p>
<hr>
<p><code>layer = Linear(4, 3)</code>相当于函数，实际上它的调用过程是<code>layer.__call__(input)</code>，在<code>__call__</code>函数中调用<code>layer.forward(x)</code>。所以尽量使用<code>layer(x)</code>而不是<code>layer.forward(x)</code></p>
<p>支持inplace的操作一般都是节省内存或者显存的。</p>
<h3 id="5-PyTorch中常用的工具"><a href="#5-PyTorch中常用的工具" class="headerlink" title="5 PyTorch中常用的工具"></a>5 PyTorch中常用的工具</h3><p>在训练神经网络的过程中需要用到很多工具，其中最重要的三部分是数据、可视化和GPU加速。</p>
<h4 id="5-1-数据处理"><a href="#5-1-数据处理" class="headerlink" title="5.1 数据处理"></a>5.1 数据处理</h4><p><strong>数据加载</strong></p>
<p>在PyTorch中，数据加载可通过自定义的数据集对象实现。数据集对象被抽象为Dataset类，实现自定义的数据集需要继承Dataset，并实现两个Python的魔法方法。</p>
<ul>
<li><code>__getitem__</code>：返回一条数据或一个样本。<code>obj[index]</code>等价于<code>obj.__getitem__(index)</code></li>
<li><code>__len__</code>：返回样本的数量。<code>len(obj)</code>等价于<code>obj.__len()</code></li>
</ul>
<p>DataLoader里没有太多的魔法方法，他封装了Python的标准库multiprocessing,使其能够实现多进程加速。在Dataset和Dataloader的使用方法有如下建议。</p>
<ul>
<li>高负载的操作放在<code>__getitem__</code>中，如加载图片；</li>
<li>dataset中应尽量只包含只读对象，避免修改任何可变对象；</li>
</ul>
<p>在从事大多数深度学习研究时，程序都需要实现以下几个功能。</p>
<ul>
<li>模型定义 </li>
<li>数据处理和加载</li>
<li>训练模型（Train &amp; Validate）</li>
<li>训练过程的可视化</li>
<li>测试（Test / Inference）</li>
</ul>
<p>此外，程序还应该满足以下几个要求：模型需具有高度的可配置性，便于修改参数，修改模型和反复实验；代码应具有良好的组织结构，使人一目了然；代码应具有良好的说明，使其他人能够理解。</p>
<p>上述过程中，最重要的是模型定义、数据加载、训练和测试</p>
<h4 id="5-2-使用GPU加速-CUDA"><a href="#5-2-使用GPU加速-CUDA" class="headerlink" title="5.2 使用GPU加速:CUDA"></a>5.2 使用GPU加速:CUDA</h4><p>在PyTorch中，一下数据结构分为CPU和GPU两个版本：Tensor、Variable(包括Parameter)、nn.Module(包括常用的layer、loss function、以及容器Sequential等)</p>
<p>它们都带有一个.cuda方法，调用此方法即可将其转为对应的GPU对象。注意，tensor.cuda和variable.cuda都会返回一个新对象，这个新对象的数据已转移至GPU，而之前的tensor/variable的数据还在原来的设备上（CPU）。module.cuda会将所有的数据都迁移至GPU，并返回自己。所以module = module.cuda() 和 module.cuda() 的效果相同。</p>
<p>Variable和nn.Module在GPU和CPU之间的转换，本质上还是利用了Tensor在GPU和CPU之间的转换。Variable.cuda操作实际上是将variable.data转移至指定的GPU。而nn.Module的cuda方法是将nn.Module下的所有parameter（包括子module的parameter）都转移至GPU，而Partameter本质上也是Variable。</p>
<p>关于使用GPU的一些建议：</p>
<ul>
<li>GPU运算很快，但是运算量小时，并不能体现他的优势，因此一些简单的操作直接用CPU完成；</li>
<li>数据在CPU和GPU之间的传递比较耗时，应当尽量避免；</li>
<li>在进行低精度的运算时，可以考虑HalfTensor，相比FloatTensor能节省一半的显存，但是千万注意数据溢出的情况；</li>
</ul>
<p>大部分的损失函数也都属于nn.Module，但在使用GPU时，很多时候我们忘记使用它的.cuda方法，在大多数情况下不会报错，因为损失函数本身没有可学习的参数。但是某些情况下会出现问题，为了保险起见同时也为了代码更规范，应记得调用criterion.cuda。</p>
<h4 id="5-3-持久化"><a href="#5-3-持久化" class="headerlink" title="5.3 持久化"></a>5.3 持久化</h4><p>在PyTorch中，一下对象可以持久化到硬盘，并通过相应的方法加载到内存中。</p>
<p>Tensor、Variable、nn.Module、Optimizer</p>
<p>本质上，上述这些信息最终都是保存成Tensor。Tensor的保存和加载十分简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的pickle模块，在load时还可以将GPU tensor映射到CPU或其他GPU上。</p>
<h4 id="5-4-ipdb"><a href="#5-4-ipdb" class="headerlink" title="5.4 ipdb"></a>5.4 ipdb</h4><p>关于ipdb的使用还有一些技巧：</p>
<ul>
<li>&lt;tab&gt;键能够自动补齐，补齐用法和IPython中的类似；</li>
<li>j(ump) &lt;lineno&gt;能够跳过中间某些行代码的执行；</li>
<li>h(elp)能够查看调试命令的用法；</li>
</ul>
<p>PyTorch和ipdb结合能完成很多其他框架不能完成或很难实现的功能：</p>
<ul>
<li>通过debug暂停程序。当程序进入debug模式之后，将不再执行GPU和CPU运算，但是内存和显存及相应的堆栈空间不会释放；</li>
<li>通过debug分析程序，查看每个层的输出，查看网络的参数情况。通过u(p)、d(own)、s(tep)等命令，能够进入指定的代码，通过n(ext)可以单步执行，从而看到每一层的运算结果，便于分析网络的数值分布等信息。</li>
<li>作为动态图框架，PyTorch拥有Python动态语言解释执行的优点，我们能够在运行程序时，通过ipdb修改某些变量的值或属性，这些修改能够立即生效。例如可以在训练不久根据损失函数调整学习率，不必重启程序。</li>
</ul>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="http://cheertt.top" target="_blank">cheertt</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
    
        <a href="/p/39949.html" class="next-post btn btn-default" title='cs231n的NumPy教程'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">cs231n的NumPy教程</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: 'xOKV9J4UeQAtVkvnJC7Kq2Jn-gzGzoHsz',
            appKey: 'erIpQac4azoCmgfBB7Dl9maa',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#0-简介"><span class="toc-text">0 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-PyTorch简介"><span class="toc-text">1 PyTorch简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-快速入门"><span class="toc-text">2 快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Tensor"><span class="toc-text">2.1 Tensor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-autograd"><span class="toc-text">2.2 autograd</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-神经网络"><span class="toc-text">2.3 神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-数据加载与预处理"><span class="toc-text">2.4 数据加载与预处理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Tensor和autograd"><span class="toc-text">3 Tensor和autograd</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-Tensor"><span class="toc-text">3.1 Tensor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-autograd"><span class="toc-text">3.2 autograd</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-神经网络工具箱nn"><span class="toc-text">4 神经网络工具箱nn</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-PyTorch中常用的工具"><span class="toc-text">5 PyTorch中常用的工具</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-数据处理"><span class="toc-text">5.1 数据处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-使用GPU加速-CUDA"><span class="toc-text">5.2 使用GPU加速:CUDA</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-持久化"><span class="toc-text">5.3 持久化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-4-ipdb"><span class="toc-text">5.4 ipdb</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
        访问量:
        <strong id="busuanzi_value_site_pv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
        &nbsp; | &nbsp;
        访客数:
        <strong id="busuanzi_value_site_uv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>






    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>